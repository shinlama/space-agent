"""
Streamlit UI êµ¬ì„± ëª¨ë“ˆ
"""
import streamlit as st
import pandas as pd
import re
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from pathlib import Path
try:
    import folium
    from streamlit_folium import st_folium
    HAS_FOLIUM = True
except ImportError:
    HAS_FOLIUM = False

try:
    import plotly.graph_objects as go
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False
from modules.config import ALL_FACTORS, SIMILARITY_THRESHOLD, CAFE_INFO_CSV

# Streamlit ë²„ì „ í˜¸í™˜ì„± ì²˜ë¦¬
def get_dataframe_width_param():
    """
    Streamlit ë²„ì „ì— ë”°ë¼ ì ì ˆí•œ width íŒŒë¼ë¯¸í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì‹¤ì œë¡œ width='stretch'ë¥¼ ì‹œë„í•˜ê³ , ì‹¤íŒ¨í•˜ë©´ use_container_widthë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    # ì•ˆì „í•˜ê²Œ use_container_width ì‚¬ìš© (ëª¨ë“  ë²„ì „ì—ì„œ ì§€ì›)
    return {'use_container_width': True}
from modules.sentiment import run_sentiment_analysis
from modules.score import calculate_place_scores, calculate_final_research_metrics
from modules.preprocess import load_csv_raw, is_numeric_only, is_metadata_only, truncate_text_for_bert
from modules.sentiment import process_sentiment_result

# í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ (ì„ íƒì , ì§€ì—° ì´ˆê¸°í™”)
HAS_KONLPY = False
okt = None

def _init_konlpy():
    """konlpyë¥¼ ì§€ì—° ì´ˆê¸°í™”í•©ë‹ˆë‹¤. Javaê°€ ì—†ìœ¼ë©´ Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global HAS_KONLPY, okt
    if HAS_KONLPY and okt is not None:
        return okt
    
    try:
        from konlpy.tag import Okt
        okt = Okt()
        HAS_KONLPY = True
        return okt
    except (ImportError, Exception) as e:
        HAS_KONLPY = False
        okt = None
        return None


def render_data_preview(file_path, sentiment_pipeline, sentiment_model_name, tab_suffix=""):
    """ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜ ë Œë”ë§
    
    Args:
        file_path: CSV íŒŒì¼ ê²½ë¡œ
        sentiment_pipeline: ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸
        sentiment_model_name: ê°ì„± ë¶„ì„ ëª¨ë¸ ì´ë¦„
        tab_suffix: íƒ­ë³„ êµ¬ë¶„ì„ ìœ„í•œ ì ‘ë¯¸ì‚¬ (ë²„íŠ¼ key ì¤‘ë³µ ë°©ì§€ìš©)
    """
    st.header("ğŸ“‹ ë¦¬ë·° ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    
    # ì „ì²´ ë°ì´í„° ë¡œë“œ (ë¯¸ë¦¬ë³´ê¸°ìš©, ì›ë³¸ ì»¬ëŸ¼ëª… ìœ ì§€)
    df_preview = load_csv_raw(file_path)
    
    # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸ ë° ì„ íƒ
    required_cols = ['ìƒí˜¸ëª…', 'ì‹œêµ°êµ¬ëª…', 'í–‰ì •ë™ëª…', 'í‰ì ', 'ë¦¬ë·°']
    available_cols = [col for col in required_cols if col in df_preview.columns]
    
    if len(available_cols) == len(required_cols):
        # í–‰ì •êµ¬ë³„ë¡œ ì •ë ¬ (ì‹œêµ°êµ¬ëª…, ìƒí˜¸ëª…, í–‰ì •ë™ëª… ìˆœ)
        df_preview_sorted = df_preview[available_cols].copy()
        df_preview_sorted = df_preview_sorted.sort_values(by=['ì‹œêµ°êµ¬ëª…', 'ìƒí˜¸ëª…', 'í–‰ì •ë™ëª…'], ascending=[True, True, True])
        
        # í‘œë¥¼ í™”ë©´ ì „ì²´ ë„ˆë¹„ë¡œ í‘œì‹œí•˜ê¸° ìœ„í•œ CSS ìŠ¤íƒ€ì¼
        st.markdown("""
<style>
        .stDataFrame {
            width: 100% !important;
        }
        div[data-testid="stDataFrame"] {
            width: 100% !important;
    }
</style>
""", unsafe_allow_html=True)

        st.dataframe(
            df_preview_sorted,
            hide_index=True,
            **get_dataframe_width_param()
        )
        st.caption(f"ì „ì²´ {len(df_preview_sorted):,}ê°œ ë¦¬ë·° (í–‰ì •êµ¬ë³„ ì •ë ¬)")
        
        # ê°ì„± ë¶„ì„ ì¶”ê°€ ë²„íŠ¼
        st.markdown("---")
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if 'preview_sentiment_result' in st.session_state and st.session_state.preview_sentiment_result is not None:
            df_preview_with_sentiment = st.session_state.preview_sentiment_result
            st.success(f"âœ… ê°ì„± ë¶„ì„ ê²°ê³¼ (ì´ {len(df_preview_with_sentiment):,}ê°œ ë¦¬ë·°)")
            
            # ê²°ê³¼ í‘œì‹œ
            st.dataframe(
                df_preview_with_sentiment,
                hide_index=True,
            )
            
            # í†µê³„ ì •ë³´
            sentiment_labels = df_preview_with_sentiment['ê°ì„±ë¶„ì„'].tolist()
            col1, col2, col3 = st.columns(3)
            with col1:
                positive_count = sentiment_labels.count('ê¸ì •')
                st.metric("ê¸ì • ë¦¬ë·°", f"{positive_count:,}ê°œ ({positive_count/len(sentiment_labels)*100:.1f}%)")
            with col2:
                negative_count = sentiment_labels.count('ë¶€ì •')
                st.metric("ë¶€ì • ë¦¬ë·°", f"{negative_count:,}ê°œ ({negative_count/len(sentiment_labels)*100:.1f}%)")
            with col3:
                neutral_count = sentiment_labels.count('ì¤‘ë¦½')
                if neutral_count > 0:
                    st.metric("ì¤‘ë¦½ ë¦¬ë·°", f"{neutral_count:,}ê°œ ({neutral_count/len(sentiment_labels)*100:.1f}%)")
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            csv = df_preview_with_sentiment.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "ğŸ“¥ ê°ì„± ë¶„ì„ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="google_reviews_with_sentiment.csv",
                mime="text/csv",
                key=f"download_preview_sentiment{tab_suffix}"
            )
            
            # ì¬ì‹¤í–‰ ë²„íŠ¼
            if st.button("ğŸ”„ ê°ì„± ë¶„ì„ ë‹¤ì‹œ ì‹¤í–‰", type="secondary", key=f"preview_sentiment_rerun{tab_suffix}"):
                st.session_state.preview_sentiment_result = None
                st.rerun()
        else:
            # ê°ì„± ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
            if st.button("ğŸ” ê°ì„± ë¶„ì„ ì¶”ê°€ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)", type="secondary", key=f"preview_sentiment_analyze{tab_suffix}"):
                _run_preview_sentiment_analysis(df_preview_sorted, sentiment_pipeline, sentiment_model_name)
    else:
        st.warning(f"í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(df_preview.columns)}")


def _run_preview_sentiment_analysis(df_preview_sorted, sentiment_pipeline, sentiment_model_name):
    """ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜ì˜ ê°ì„± ë¶„ì„ ì‹¤í–‰"""
    with st.spinner(f"ê°ì„± ë¶„ì„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ë·°ë³„ ê°ì„± ë¶„ì„ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
        # ë¦¬ë·° í…ìŠ¤íŠ¸ ë° í‰ì  ì¶”ì¶œ
        review_texts = df_preview_sorted['ë¦¬ë·°'].astype(str).tolist()
        ratings = df_preview_sorted['í‰ì '].astype(float).tolist() if 'í‰ì ' in df_preview_sorted.columns else [None] * len(review_texts)
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        batch_size = 32
        total_batches = (len(review_texts) + batch_size - 1) // batch_size
        
        sentiment_labels = []
        sentiment_scores = []
        
        for batch_idx in range(total_batches):
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, len(review_texts))
            batch_texts = review_texts[start_idx:end_idx]
            batch_ratings = ratings[start_idx:end_idx] if ratings else [None] * len(batch_texts)
            
            progress = (batch_idx + 1) / total_batches
            progress_bar.progress(progress)
            status_text.text(f"ì²˜ë¦¬ ì¤‘: {batch_idx + 1}/{total_batches} ë°°ì¹˜ ({len(batch_texts)}ê°œ ë¦¬ë·°)")
            
            try:
                # ìˆ«ì-only ë¦¬ë·°ì™€ ì¼ë°˜ í…ìŠ¤íŠ¸ ë¦¬ë·° ë¶„ë¦¬
                text_batch = []
                batch_results_map = {}
                
                for idx, text in enumerate(batch_texts):
                    rating = batch_ratings[idx] if idx < len(batch_ratings) else None
                    
                    # ìˆ«ì-only ë¦¬ë·°ëŠ” ë³„ì  ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬
                    if is_numeric_only(text):
                        try:
                            rating_value = float(text)
                            if rating_value >= 4.0:
                                batch_results_map[idx] = ("ê¸ì •", 0.9)
                            elif rating_value >= 3.0:
                                batch_results_map[idx] = ("ì¤‘ë¦½", 0.5)
                            else:
                                batch_results_map[idx] = ("ë¶€ì •", 0.1)
                        except ValueError:
                            batch_results_map[idx] = ("ì¤‘ë¦½", 0.5)
                    # ë©”íƒ€ë°ì´í„°-only ë¦¬ë·°ë„ ë³„ì  ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬
                    elif is_metadata_only(text) and rating is not None:
                        try:
                            rating_value = float(rating)
                            if rating_value >= 4.0:
                                batch_results_map[idx] = ("ê¸ì •", 0.9)
                            elif rating_value >= 3.0:
                                batch_results_map[idx] = ("ì¤‘ë¦½", 0.5)
                            else:
                                batch_results_map[idx] = ("ë¶€ì •", 0.1)
                        except (ValueError, TypeError):
                            batch_results_map[idx] = ("ì¤‘ë¦½", 0.5)
                    else:
                        # ì¼ë°˜ í…ìŠ¤íŠ¸ ë¦¬ë·°ëŠ” ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•´ ìˆ˜ì§‘
                        text_batch.append((idx, text))
                
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ë¦¬ë·°ëŠ” ëª¨ë¸ ì‚¬ìš©
                if text_batch:
                    text_only = [text for _, text in text_batch]
                    truncated_texts = [truncate_text_for_bert(text) for text in text_only]
                    model_results = sentiment_pipeline(truncated_texts, truncation=True, max_length=512)
                    
                    # ëª¨ë¸ ê²°ê³¼ë¥¼ ì¸ë±ìŠ¤ì— ë§¤í•‘
                    for (idx, _), res in zip(text_batch, model_results):
                        label, score = process_sentiment_result(res, sentiment_model_name)
                        batch_results_map[idx] = (label, score)
                
                # ì›ë˜ ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ì¶”ê°€
                for idx in range(len(batch_texts)):
                    label, score = batch_results_map[idx]
                    sentiment_labels.append(label)
                    sentiment_scores.append(score)
                    
            except Exception as e:
                st.warning(f"ë°°ì¹˜ {batch_idx+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                sentiment_labels.extend(['ì¤‘ë¦½'] * len(batch_texts))
                sentiment_scores.extend([0.5] * len(batch_texts))
        
        progress_bar.empty()
        status_text.empty()
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        df_preview_with_sentiment = df_preview_sorted.copy()
        df_preview_with_sentiment['ê°ì„±ë¶„ì„'] = sentiment_labels
        df_preview_with_sentiment['ê°ì„±ì ìˆ˜'] = [f"{s:.3f}" for s in sentiment_scores]
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬
        column_order = ['ìƒí˜¸ëª…', 'ì‹œêµ°êµ¬ëª…', 'í–‰ì •ë™ëª…', 'í‰ì ', 'ë¦¬ë·°', 'ê°ì„±ë¶„ì„', 'ê°ì„±ì ìˆ˜']
        df_preview_with_sentiment = df_preview_with_sentiment[column_order]
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state.preview_sentiment_result = df_preview_with_sentiment
        
        st.success(f"âœ… ê°ì„± ë¶„ì„ ì™„ë£Œ! {len(sentiment_labels):,}ê°œ ë¦¬ë·° ë¶„ì„ë¨")
        st.rerun()


def render_placeness_calculation(df_reviews, sbert_model, sentiment_pipeline, sentiment_model_name):
    """ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ ê³„ì‚° ì„¹ì…˜ ë Œë”ë§"""
    st.header("ğŸ“Š 1. ì¥ì†Œì„± ìš”ì¸ë³„ ì •ëŸ‰ ì ìˆ˜ ê³„ì‚°")
    st.caption(f"ìœ ì‚¬ë„ ì„ê³„ê°’: {SIMILARITY_THRESHOLD} (ì½”ë“œ ë‚´ ê³ ì •ê°’)")
    st.caption(f"âš ï¸ ì–¸ê¸‰ 0ì¸ ìš”ì¸ì€ fsi=0.5, Wi=0 ì²˜ë¦¬ë˜ì–´ Muì— ì˜í–¥ ì—†ìŒ")
    
    total_reviews_count = len(df_reviews)
    
    if st.button("ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ ê³„ì‚° ì‹œì‘", type="primary", key="placeness_calculation_start"):
        with st.spinner("ì¥ì†Œì„± ìš”ì¸ë³„ ì ìˆ˜ ê³„ì‚° ë° ì—°êµ¬ ì§€í‘œ ì‚°ì¶œ ì¤‘..."):
            try:
                df_place_scores, df_review_scores = calculate_place_scores(
                    df_reviews.copy(), 
                    sbert_model, 
                    sentiment_pipeline, 
                    ALL_FACTORS, 
                    similarity_threshold=SIMILARITY_THRESHOLD,
                    sentiment_model_name=sentiment_model_name
                )
                
                df_final_metrics = calculate_final_research_metrics(
                    df_place_scores, 
                    list(ALL_FACTORS.keys()), 
                    total_reviews_count
                )
                
                st.session_state.df_review_scores = df_review_scores
                st.session_state.df_final_metrics = df_final_metrics
                st.session_state.df_place_scores = df_place_scores
                
            except Exception as e:
                st.error(f"ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                st.code(traceback.format_exc())
    
    # ê²°ê³¼ í‘œì‹œ
    if st.session_state.df_final_metrics is not None:
        _render_placeness_results()


def _render_placeness_results():
    """ì¥ì†Œì„± ê³„ì‚° ê²°ê³¼ í‘œì‹œ"""
    st.header("ì¥ì†Œì„± ì¢…í•© ì ìˆ˜")
    
    df_final_metrics = st.session_state.df_final_metrics
    
    # Final_PlaceScore_Summaryì™€ ê°•ì /ì•½ì ë§Œ í‘œì‹œ
    display_summary_cols = ['cafe_name', 'Final_PlaceScore_Summary', 'ê°•ì _ìš”ì¸(+df+)', 'ì•½ì _ìš”ì¸(-df-)']
    if all(col in df_final_metrics.columns for col in display_summary_cols):
        st.dataframe(
            df_final_metrics[display_summary_cols].set_index('cafe_name'), 
            **get_dataframe_width_param()
        )
    
    st.subheader("ì„¸ë¶€ ì§€í‘œ ì ìˆ˜ (fsi)")
    fsi_cols = ['cafe_name', 'ì¢…í•©_ì¥ì†Œì„±_ì ìˆ˜_Mu', 'ìš”ì¸_ì ìˆ˜_í‘œì¤€í¸ì°¨_Sigma'] + [f'ì ìˆ˜_{factor}' for factor in ALL_FACTORS.keys()]
    if all(col in df_final_metrics.columns for col in fsi_cols):
        st.dataframe(
            df_final_metrics[fsi_cols].set_index('cafe_name'), 
            **get_dataframe_width_param()
        )
    
    # ê°€ì¤‘ì¹˜ ì •ë³´ í‘œì‹œ
    with st.expander("ğŸ“Š ê°€ì¤‘ì¹˜ (Wi) ìƒì„¸ ì •ë³´"):
        wi_cols = ['cafe_name'] + [f'Wi_{factor}' for factor in ALL_FACTORS.keys()]
        if all(col in df_final_metrics.columns for col in wi_cols):
            st.dataframe(
                df_final_metrics[wi_cols].set_index('cafe_name'), 
                **get_dataframe_width_param()
            )
    
    # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
    csv = df_final_metrics.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "ì¥ì†Œì„± ìµœì¢… ì—°êµ¬ ì§€í‘œ CSV ë‹¤ìš´ë¡œë“œ (Wi, Mu, Sigma í¬í•¨)",
        data=csv,
        file_name="placeness_final_research_metrics.csv",
        mime="text/csv"
    )


def render_sentiment_analysis(df_reviews, sentiment_pipeline, sentiment_model_name):
    """ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ì„¹ì…˜ ë Œë”ë§"""
    st.header("2. ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ë° ì¹´í˜ë³„ í‰ê· ")
    
    if st.button("KoBERT ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ì‹œì‘", type="primary", key="sentiment_analysis_start"):
        with st.spinner("ê°œë³„ ë¦¬ë·° ê¸ì •/ë¶€ì • ê°ì„± ì ìˆ˜ ê³„ì‚° ì¤‘ (KoBERT/KoELECTRA)..."):
            try:
                df_reviews_with_sentiment, df_avg_sentiment = run_sentiment_analysis(
                    df_reviews.copy(), 
                    sentiment_pipeline,
                    sentiment_model_name
                )
                
                st.session_state.df_reviews_with_sentiment = df_reviews_with_sentiment
                st.session_state.df_avg_sentiment = df_avg_sentiment
                
            except Exception as e:
                st.error(f"ê°ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                st.code(traceback.format_exc())
    
    # ê²°ê³¼ í‘œì‹œ
    if st.session_state.df_reviews_with_sentiment is not None and st.session_state.df_avg_sentiment is not None:
        st.subheader("âœ… ì¹´í˜ë³„ í‰ê·  ê°ì„± ì ìˆ˜")
        st.dataframe(st.session_state.df_avg_sentiment.set_index('cafe_name'), **get_dataframe_width_param())
        
        st.subheader("âœ… ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ê²°ê³¼ (ìƒ˜í”Œ)")
        sample_df = st.session_state.df_reviews_with_sentiment[['cafe_name', 'review_text', 'sentiment_label', 'sentiment_score']].head(20)
        st.dataframe(sample_df, **get_dataframe_width_param())
        
        # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        csv = st.session_state.df_reviews_with_sentiment.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name="review_sentiment_analysis.csv",
            mime="text/csv"
        )


def render_detailed_results():
    """ë¦¬ë·°ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì„¹ì…˜ ë Œë”ë§"""
    st.header("ğŸ“Š ë¦¬ë·°ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    
    has_sentiment = st.session_state.df_reviews_with_sentiment is not None
    has_placeness = st.session_state.df_review_scores is not None
    
    if not has_sentiment and not has_placeness:
        st.info("ğŸ‘† ìœ„ì˜ ë‘ ë¶„ì„ì„ ëª¨ë‘ ì‹¤í–‰í•˜ë©´ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        if has_sentiment and has_placeness:
            _render_merged_results()
        elif has_sentiment:
            st.info("ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ ê³„ì‚°ì„ ì‹¤í–‰í•˜ë©´ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # ì „ì²´ ë¦¬ë·° í‘œì‹œ
            display_cols = ['cafe_name', 'review_text', 'sentiment_label', 'sentiment_score']
            available_cols = [col for col in display_cols if col in st.session_state.df_reviews_with_sentiment.columns]
            st.dataframe(
                st.session_state.df_reviews_with_sentiment[available_cols], 
                hide_index=True, 
            )
            st.caption(f"ì´ {len(st.session_state.df_reviews_with_sentiment):,}ê°œ ë¦¬ë·°")
            
            # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            csv = st.session_state.df_reviews_with_sentiment[available_cols].to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "ğŸ“¥ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="review_sentiment_analysis.csv",
                mime="text/csv"
            )
        elif has_placeness:
            st.info("ê°ì„± ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # ì „ì²´ 12ê°œ ìš”ì¸ ì ìˆ˜ í‘œì‹œ
            factor_names = list(ALL_FACTORS.keys())
            factor_score_cols = [f'{factor}_ì ìˆ˜' for factor in factor_names]
            display_cols = ['cafe_name', 'review_text'] + factor_score_cols
            available_cols = [col for col in display_cols if col in st.session_state.df_review_scores.columns]
            
            # ì ìˆ˜ í¬ë§·íŒ… (í‘œì‹œìš©)
            display_df = st.session_state.df_review_scores[available_cols].copy()
            for col in factor_score_cols:
                if col in display_df.columns:
                    display_df[col] = display_df[col].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")
            
            st.dataframe(
                display_df, 
                hide_index=True, 
            )
            st.caption(f"ì´ {len(st.session_state.df_review_scores):,}ê°œ ë¦¬ë·° (11ê°œ ìš”ì¸ ì „ì²´ í‘œì‹œ)")
            
            # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ì›ë³¸ ë°ì´í„°, í¬ë§·íŒ… ì—†ì´)
            csv = st.session_state.df_review_scores[available_cols].to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "ğŸ“¥ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="review_placeness_scores.csv",
                mime="text/csv"
            )
            
            # ìš”ì¸ë³„ í‚¤ì›Œë“œ ë¶„ì„ ì¶”ê°€
            st.markdown("---")
            visualize_factor_keywords(st.session_state.df_review_scores, factor_names, top_n=15)


def _render_merged_results():
    """ë³‘í•©ëœ ê²°ê³¼ í‘œì‹œ"""
    df_sentiment = st.session_state.df_reviews_with_sentiment.copy()
    df_placeness = st.session_state.df_review_scores.copy()
    
    df_sentiment['review_index'] = df_sentiment.index
    df_placeness['review_index'] = df_placeness['review_index']
    
    df_merged = pd.merge(
        df_sentiment[['review_index', 'cafe_name', 'review_text', 'sentiment_label', 'sentiment_score']],
        df_placeness,
        on=['review_index', 'cafe_name', 'review_text'],
        how='outer'
    )
    
    factor_names = list(ALL_FACTORS.keys())
    factor_score_cols = [f'{factor}_ì ìˆ˜' for factor in factor_names]
    display_cols = ['cafe_name', 'review_text', 'sentiment_label', 'sentiment_score'] + factor_score_cols
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
    available_cols = [col for col in display_cols if col in df_merged.columns]
    
    # ëˆ„ë½ëœ ìš”ì¸ ì»¬ëŸ¼ í™•ì¸
    missing_factors = [f for f in factor_names if f'{f}_ì ìˆ˜' not in df_merged.columns]
    if missing_factors:
        st.warning(f"âš ï¸ ë‹¤ìŒ ìš”ì¸ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_factors)}")
    
    st.subheader("âœ… ë¦¬ë·°ë³„ ê°ì„± ë¶„ì„ + ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ (ì „ì²´ 11ê°œ ìš”ì¸)")
    st.caption(f"ì´ {len(df_merged):,}ê°œ ë¦¬ë·° ì¤‘ í•„í„°ë§ëœ ê²°ê³¼ í‘œì‹œ")
    
    # í•„í„° ì˜µì…˜
    col1, col2 = st.columns(2)
    with col1:
        selected_cafe = st.selectbox(
            "ì¹´í˜ ì„ íƒ (ì „ì²´ ë³´ê¸°)",
            options=['ì „ì²´'] + sorted(df_merged['cafe_name'].unique().tolist()),
            key="review_detail_cafe_filter"
        )
    with col2:
        selected_sentiment = st.selectbox(
            "ê°ì„± í•„í„°",
            options=['ì „ì²´', 'ê¸ì •', 'ë¶€ì •'],
            key="review_detail_sentiment_filter"
        )
    
    # í•„í„°ë§
    filtered_df = df_merged.copy()
    if selected_cafe != 'ì „ì²´':
        filtered_df = filtered_df[filtered_df['cafe_name'] == selected_cafe]
    if selected_sentiment != 'ì „ì²´':
        filtered_df = filtered_df[filtered_df['sentiment_label'] == selected_sentiment]
    
    # ê²°ê³¼ í‘œì‹œ
    if len(filtered_df) > 0:
        display_df = filtered_df[available_cols].copy()
        
        # ì ìˆ˜ í¬ë§·íŒ…
        for col in factor_score_cols:
            if col in display_df.columns:
                display_df[col] = display_df[col].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")
        
        if 'sentiment_score' in display_df.columns:
            display_df['sentiment_score'] = display_df['sentiment_score'].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")
        
        # ì „ì²´ ë¦¬ë·° í‘œì‹œ (ë†’ì´ë¥¼ í¬ê²Œ ì„¤ì •í•˜ì—¬ ìŠ¤í¬ë¡¤ ê°€ëŠ¥)
        st.dataframe(
            display_df,
            hide_index=True,
        )

        st.caption(f"ì´ {len(filtered_df):,}ê°œ ë¦¬ë·° í‘œì‹œ (11ê°œ ìš”ì¸ ì „ì²´)")
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        csv = filtered_df[available_cols].to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name="review_detailed_analysis.csv",
            mime="text/csv"
        )
        
        # ìš”ì¸ë³„ í‚¤ì›Œë“œ ë¶„ì„ ì¶”ê°€
        st.markdown("---")
        factor_names = list(ALL_FACTORS.keys())
        visualize_factor_keywords(filtered_df, factor_names, top_n=15)
    else:
        st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")


def visualize_factor_keywords(df_review_scores, factor_names, top_n=15, top_reviews_per_factor=200):
    """
    ê° ìš”ì¸ë³„ë¡œ TF-IDFë¥¼ ì´ìš©í•˜ì—¬ 'íŠ¹ìƒ‰ ìˆëŠ”' ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
    ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ ë¦¬ë·°ì—ì„œë§Œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        df_review_scores: ë¦¬ë·°ë³„ ìš”ì¸ ì ìˆ˜/ìœ ì‚¬ë„ DataFrame
        factor_names: ìš”ì¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        top_n: ìƒìœ„ Nê°œ í‚¤ì›Œë“œ í‘œì‹œ
        top_reviews_per_factor: ê° ìš”ì¸ë³„ë¡œ ìœ ì‚¬ë„ ìƒìœ„ ëª‡ ê°œ ë¦¬ë·°ë¥¼ ì‚¬ìš©í• ì§€ (ê¸°ë³¸ê°’: 200)
    """
    st.subheader("ğŸ” ìš”ì¸ë³„ í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„ (TF-IDF ê¸°ë°˜)")
    st.info(f"ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ {top_reviews_per_factor}ê°œ ë¦¬ë·°ì—ì„œë§Œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. TF-IDFë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì¥ì†Œì„± ìš”ì¸ì„ ê°€ì¥ ì˜ ëŒ€í‘œí•˜ëŠ” ì°¨ë³„í™”ëœ ë‹¨ì–´ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    
    # 1. ìš”ì¸ë³„ í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    # ê° ìš”ì¸ì— ë§¤ì¹­ëœ ë¦¬ë·° ì¤‘ ìœ ì‚¬ë„ ìƒìœ„ ë¦¬ë·°ë§Œ ì‚¬ìš©
    factor_documents = []
    valid_factors = []  # ë¦¬ë·°ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” ìš”ì¸ë§Œ ì¶”ì 
    
    for factor in factor_names:
        score_col = f'{factor}_ì ìˆ˜'
        sim_col = f'{factor}_ìœ ì‚¬ë„'
        
        if score_col not in df_review_scores.columns:
            factor_documents.append("")
            continue
            
        # í•´ë‹¹ ìš”ì¸ì— ë§¤ì¹­ëœ ë¦¬ë·°ë§Œ í•„í„°ë§
        relevant_df = df_review_scores[
            pd.to_numeric(df_review_scores[score_col], errors='coerce').notnull()
        ].copy()
        
        if not relevant_df.empty:
            # ìœ ì‚¬ë„ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ, ì—†ìœ¼ë©´ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            if sim_col in relevant_df.columns:
                # ìœ ì‚¬ë„ ìƒìœ„ ë¦¬ë·°ë§Œ ì„ íƒ
                top_relevant_df = relevant_df.sort_values(by=sim_col, ascending=False).head(top_reviews_per_factor)
            else:
                # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                top_relevant_df = relevant_df.sort_values(by=score_col, ascending=False).head(top_reviews_per_factor)
            
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (í•œê¸€ë§Œ ë‚¨ê¸°ê¸°)
            text = " ".join(top_relevant_df['review_text'].astype(str).tolist())
            text = re.sub(r'[^ê°€-í£\s]', '', text)  # í•œê¸€ê³¼ ê³µë°±ë§Œ ë‚¨ê¹€
            factor_documents.append(text)
            valid_factors.append(factor)
        else:
            # ë§¤ì¹­ëœ ë¦¬ë·°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ì¶”ê°€ (ì¸ë±ìŠ¤ ìœ ì§€ë¥¼ ìœ„í•´)
            factor_documents.append("")
    
    if not any(factor_documents):
        st.warning("ë¶„ì„í•  í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 2. TF-IDF ë²¡í„°í™”
    # ë¶ˆìš©ì–´ ì„¤ì • (ëª¨ë“  ìš”ì¸ì—ì„œ ê³µí†µì ìœ¼ë¡œ ë„ˆë¬´ ë§ì´ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ë“¤ ì œê±°)
    stop_words = [
        'ì¹´í˜', 'ë„ˆë¬´', 'ì§„ì§œ', 'ì •ë§', 'ë§ì´', 'ê°€ì„œ', 'ë¨¹ê³ ', 'ìˆëŠ”', 'í•˜ëŠ”', 'ê·¸ë¦¬ê³ ', 'ê·¸ë˜ì„œ', 
        'ì¢‹ì•„ìš”', 'ìˆì–´ìš”', 'ê°™ì•„ìš”', 'ë§›ìˆì–´ìš”', 'ë¶„ìœ„ê¸°', 'ìƒê°', 'ëŠë‚Œ', 'ë°©ë¬¸', 'ê³³', 'ê²ƒ', 'ìˆ˜',
        'ìˆìŠµë‹ˆë‹¤', 'ìˆì—ˆ', 'ìˆê³ ', 'ìˆëŠ”ë°', 'ìˆì–´ì„œ', 'ìˆì–´', 'ìˆìŒ',
        'ì¢‹ìŠµë‹ˆë‹¤', 'ì¢‹ì•˜', 'ì¢‹ê³ ', 'ì¢‹ì€', 'ì¢‹ì•„', 'ì¢‹ë‹¤', 'ì¢‹ìŒ',
        'ë§›ìˆìŠµë‹ˆë‹¤', 'ë§›ìˆì—ˆ', 'ë§›ìˆê³ ', 'ë§›ìˆëŠ”', 'ë§›ìˆì–´',
        'ì´ê±°', 'ê·¸ê±°', 'ì €ê±°', 'ì´ê²ƒ', 'ê·¸ê²ƒ', 'ì €ê²ƒ',
        'ê·¸ëŸ°ë°', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜',
        'ì´ëŸ°', 'ê·¸ëŸ°', 'ì €ëŸ°', 'ì´ë ‡ê²Œ', 'ê·¸ë ‡ê²Œ', 'ì €ë ‡ê²Œ',
        'ë•Œë¬¸', 'ìœ„í•´', 'í†µí•´', 'ëŒ€í•´', 'ê´€ë ¨', 'ë”°ë¼',
        'ìë¦¬', 'ìë¦¬ê°€', 'ìë¦¬ë„', 'ìë¦¬ë¥¼', 'ìë¦¬ì—',
        'ë§¤ì¥', 'ë§¤ì¥ì´', 'ë§¤ì¥ë„', 'ë§¤ì¥ì„', 'ë§¤ì¥ì—',
        'ì‚¬ëŒ', 'ì‚¬ëŒì´', 'ì‚¬ëŒë“¤', 'ì‚¬ëŒë„',
        # ìŒë£Œ/ìŒì‹ ê´€ë ¨ ì¼ë°˜ ë‹¨ì–´
        'ì»¤í”¼', 'ì»¤í”¼ë„', 'ì»¤í”¼ë¥¼', 'ì»¤í”¼ê°€', 'ì»¤í”¼ëŠ”',
        'ìŒë£Œ', 'ìŒë£Œë„', 'ìŒë£Œë¥¼',
        'ë””ì €íŠ¸', 'ë””ì €íŠ¸ë„',
        # ì¼ë°˜ í˜•ìš©ì‚¬/ë¶€ì‚¬
        'ë‹¤ì–‘í•œ', 'ë‹¤ì–‘', 'ë‹¤ë¥¸', 'ë§¤ìš°', 'ì•„ì£¼', 'ì •ë§ë¡œ',
        'ìˆë‹¤', 'ìˆì–´', 'ìˆê³ ', 'ìˆëŠ”ë°', 'ìˆì–´ì„œ', 'ìˆìŒ'
    ]
    
    try:
        tfidf_vectorizer = TfidfVectorizer(
            max_features=1000, 
            stop_words=stop_words,
            token_pattern=r"(?u)\b\w\w+\b"  # 2ê¸€ì ì´ìƒ ë‹¨ì–´ë§Œ
        )
        tfidf_matrix = tfidf_vectorizer.fit_transform(factor_documents)
        feature_names = tfidf_vectorizer.get_feature_names_out()
    except ValueError as e:
        st.warning(f"TF-IDF ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜, ëª¨ë“  ë‹¨ì–´ê°€ ë¶ˆìš©ì–´ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
        return
    
    # 3. ì‹œê°í™”
    tabs = st.tabs(factor_names)
    
    for i, factor in enumerate(factor_names):
        with tabs[i]:
            score_col = f'{factor}_ì ìˆ˜'
            sim_col = f'{factor}_ìœ ì‚¬ë„'
            
            if score_col not in df_review_scores.columns:
                st.warning(f"ë°ì´í„°ì— {score_col} ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # í•´ë‹¹ ìš”ì¸ ì ìˆ˜ê°€ ìˆëŠ”(ë§¤ì¹­ëœ) ë¦¬ë·°ë“¤ë§Œ ì¶”ì¶œ
            relevant_df = df_review_scores[
                pd.to_numeric(df_review_scores[score_col], errors='coerce').notnull()
            ].copy()
            
            if relevant_df.empty or not factor_documents[i].strip():
                st.write("ë§¤ì¹­ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # -------------------------------------------------------
            # [ê²€ì¦ ë°©ë²• 1] ìœ ì‚¬ë„ ìƒìœ„ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
            # -------------------------------------------------------
            st.markdown(f"#### 1. '{factor}'ì™€ ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ë¦¬ë·° Top 10")
            
            # ìœ ì‚¬ë„ ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì‚¬ìš©, ì—†ë‹¤ë©´ ì ìˆ˜ ê¸°ì¤€
            if sim_col in relevant_df.columns:
                top_reviews = relevant_df.sort_values(by=sim_col, ascending=False).head(10)
                for idx, row in top_reviews.iterrows():
                    score_val = row[score_col] if pd.notna(row[score_col]) else "N/A"
                    sim_val = row[sim_col] if pd.notna(row[sim_col]) else "N/A"
                    st.success(f"**ìœ ì‚¬ë„ {sim_val:.3f} | ì ìˆ˜ {score_val:.3f}**: {row['review_text']}")
            else:
                st.warning("ìœ ì‚¬ë„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.")
                top_reviews = relevant_df.sort_values(by=score_col, ascending=False).head(10)
                for idx, row in top_reviews.iterrows():
                    score_val = row[score_col] if pd.notna(row[score_col]) else "N/A"
                    st.success(f"**ì ìˆ˜ {score_val:.3f}**: {row['review_text']}")
            
            # -------------------------------------------------------
            # [ê²€ì¦ ë°©ë²• 2] TF-IDF ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ì„ (Bar Chart)
            # -------------------------------------------------------
            st.markdown(f"#### 2. '{factor}' ê´€ë ¨ ë¦¬ë·° ë‚´ ì£¼ìš” í‚¤ì›Œë“œ")
            
            # í•´ë‹¹ ìš”ì¸(ë¬¸ì„œ)ì˜ TF-IDF ì ìˆ˜ ê°€ì ¸ì˜¤ê¸°
            tfidf_scores = tfidf_matrix[i].toarray().flatten()
            
            # í•´ë‹¹ ìš”ì¸ ë‚´ì—ì„œì˜ ë‹¨ì–´ ë¹ˆë„ë„ ê³„ì‚° (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)
            # TF-IDF ì ìˆ˜ì™€ ìš”ì¸ ë‚´ ë¹ˆë„ë¥¼ ê²°í•©í•˜ì—¬ ë” ì •í™•í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            factor_text = factor_documents[i]
            factor_word_counts = Counter(factor_text.split())
            total_words_in_factor = sum(factor_word_counts.values())
            
            # TF-IDF ì ìˆ˜ì™€ ìš”ì¸ ë‚´ ìƒëŒ€ ë¹ˆë„ë¥¼ ê²°í•©í•œ ì ìˆ˜ ê³„ì‚°
            hybrid_scores = []
            for idx, word in enumerate(feature_names):
                tfidf_score = tfidf_scores[idx]
                # í•´ë‹¹ ìš”ì¸ ë‚´ì—ì„œì˜ ìƒëŒ€ ë¹ˆë„ (0~1)
                word_freq_in_factor = factor_word_counts.get(word, 0) / max(total_words_in_factor, 1)
                # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜: TF-IDF * (1 + ìš”ì¸ ë‚´ ìƒëŒ€ ë¹ˆë„)
                # ì´ë ‡ê²Œ í•˜ë©´ TF-IDFê°€ ë†’ê³  í•´ë‹¹ ìš”ì¸ì—ì„œë„ ìì£¼ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ê°€ ìš°ì„ ìˆœìœ„ê°€ ë†’ì•„ì§
                hybrid_score = tfidf_score * (1 + word_freq_in_factor * 2)
                if hybrid_score > 0:
                    hybrid_scores.append((word, hybrid_score, tfidf_score, word_freq_in_factor))
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            hybrid_scores.sort(key=lambda x: x[1], reverse=True)
            top_keywords = hybrid_scores[:top_n]
            
            if top_keywords:
                # ë°ì´í„°í”„ë ˆì„ ë³€í™˜ (í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì‚¬ìš©)
                df_keywords = pd.DataFrame(
                    [(word, hybrid_score) for word, hybrid_score, _, _ in top_keywords],
                    columns=['ë‹¨ì–´', 'í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜']
                )
                df_keywords = df_keywords.sort_values('í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜', ascending=True)
                
                # Streamlit Bar Chart
                st.bar_chart(df_keywords.set_index('ë‹¨ì–´'), height=400)
                
                # ìƒì„¸ í…Œì´ë¸” (TF-IDF ì ìˆ˜ì™€ ë¹ˆë„ ì •ë³´ í¬í•¨)
                with st.expander("ìƒì„¸ í‚¤ì›Œë“œ ì ìˆ˜ ë³´ê¸°"):
                    df_detail = pd.DataFrame(
                        [(word, f"{hybrid_score:.4f}", f"{tfidf_score:.4f}", f"{freq:.4f}") 
                         for word, hybrid_score, tfidf_score, freq in top_keywords],
                        columns=['ë‹¨ì–´', 'í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜', 'TF-IDF ì ìˆ˜', 'ìš”ì¸ ë‚´ ìƒëŒ€ ë¹ˆë„']
                    )
                    st.dataframe(df_detail, hide_index=True, **get_dataframe_width_param())
                    st.caption("í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ = TF-IDF Ã— (1 + ìš”ì¸ ë‚´ ìƒëŒ€ ë¹ˆë„ Ã— 2)")
            else:
                st.write("ìœ ì˜ë¯¸í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            # -------------------------------------------------------
            # [ê²€ì¦ ë°©ë²• 3] ê¸ì • ë¦¬ë·°ë§Œ í•„í„°ë§í•˜ì—¬ ë³´ê¸°
            # -------------------------------------------------------
            st.markdown(f"#### 3. '{factor}' ì ìˆ˜ê°€ ë†’ì€(0.9 ì´ìƒ) ê¸ì • ë¦¬ë·° íŒ¨í„´")
            high_score_df = relevant_df[
                pd.to_numeric(relevant_df[score_col], errors='coerce') >= 0.9
            ]
            
            if not high_score_df.empty:
                display_cols = ['review_text', score_col]
                if sim_col in high_score_df.columns:
                    display_cols.insert(1, sim_col)
                st.dataframe(
                    high_score_df[display_cols].sort_values(by=score_col, ascending=False),
                    hide_index=True,
                )
                st.caption(f"ì´ {len(high_score_df)}ê°œ ë¦¬ë·° (ì ìˆ˜ 0.9 ì´ìƒ)")
            else:
                st.info("0.9ì  ì´ìƒì˜ ë§¤ìš° ê¸ì •ì ì¸ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # -------------------------------------------------------
            # [ê²€ì¦ ë°©ë²• 4] í†µê³„ ì •ë³´
            # -------------------------------------------------------
            st.markdown(f"#### 4. '{factor}' ê´€ë ¨ í†µê³„")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ê´€ë ¨ ë¦¬ë·° ìˆ˜", f"{len(relevant_df):,}ê°œ")
            with col2:
                avg_score = pd.to_numeric(relevant_df[score_col], errors='coerce').mean()
                st.metric("í‰ê·  ì ìˆ˜", f"{avg_score:.3f}" if pd.notna(avg_score) else "N/A")
            with col3:
                if sim_col in relevant_df.columns:
                    avg_sim = pd.to_numeric(relevant_df[sim_col], errors='coerce').mean()
                    st.metric("í‰ê·  ìœ ì‚¬ë„", f"{avg_sim:.3f}" if pd.notna(avg_sim) else "N/A")
                else:
                    st.metric("í‰ê·  ìœ ì‚¬ë„", "N/A")
            with col4:
                high_count = len(relevant_df[pd.to_numeric(relevant_df[score_col], errors='coerce') >= 0.9])
                st.metric("ê¸ì • ë¦¬ë·° (â‰¥0.9)", f"{high_count}ê°œ")
            
            # -------------------------------------------------------
            # [ê²€ì¦ ë°©ë²• 5] í–‰ì •êµ¬ë³„ ìƒìœ„ 10% ì¹´í˜ ë¶„í¬ ì‹œê°í™”
            # -------------------------------------------------------
            st.markdown(f"#### 5. '{factor}' ì ìˆ˜ ìƒìœ„ 10% ì¹´í˜ í–‰ì •êµ¬ë³„ ë¶„í¬")
            
            # df_place_scoresì—ì„œ í•´ë‹¹ ìš”ì¸ ì ìˆ˜ ìƒìœ„ 10% ì¹´í˜ ì¶”ì¶œ
            if 'df_place_scores' in st.session_state and st.session_state.df_place_scores is not None:
                df_place_scores = st.session_state.df_place_scores
                factor_score_col = f'ì ìˆ˜_{factor}'
                
                if factor_score_col in df_place_scores.columns:
                    # ì ìˆ˜ê°€ ìˆëŠ” ì¹´í˜ë§Œ í•„í„°ë§
                    valid_scores = df_place_scores[
                        pd.to_numeric(df_place_scores[factor_score_col], errors='coerce').notna()
                    ].copy()
                    
                    if not valid_scores.empty:
                        # ìƒìœ„ 10% ì„ê³„ê°’ ê³„ì‚°
                        threshold = valid_scores[factor_score_col].quantile(0.9)
                        top_10_percent = valid_scores[valid_scores[factor_score_col] >= threshold].copy()
                        
                        # ì›ë³¸ ë°ì´í„°ì—ì„œ ì‹œêµ°êµ¬ëª… ê°€ì ¸ì˜¤ê¸°
                        df_reviews_for_district = None
                        if 'df_reviews' in st.session_state and st.session_state.df_reviews is not None:
                            df_reviews_for_district = st.session_state.df_reviews.copy()
                        
                        # ì‹œêµ°êµ¬ëª… ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì›ë³¸ CSVì—ì„œ ë¡œë“œ
                        if df_reviews_for_district is None or 'ì‹œêµ°êµ¬ëª…' not in df_reviews_for_district.columns:
                            try:
                                from pathlib import Path
                                from modules.config import GOOGLE_REVIEW_SAMPLE_CSV
                                df_reviews_for_district = load_csv_raw(Path(GOOGLE_REVIEW_SAMPLE_CSV))
                                
                                # ì»¬ëŸ¼ëª… ì •ê·œí™” (ìƒí˜¸ëª… -> cafe_name)
                                if 'ìƒí˜¸ëª…' in df_reviews_for_district.columns and 'cafe_name' not in df_reviews_for_district.columns:
                                    df_reviews_for_district['cafe_name'] = df_reviews_for_district['ìƒí˜¸ëª…']
                            except Exception as e:
                                st.warning(f"ì‹œêµ°êµ¬ëª… ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                                df_reviews_for_district = None
                        
                        if df_reviews_for_district is not None and 'ì‹œêµ°êµ¬ëª…' in df_reviews_for_district.columns:
                            # cafe_name ì»¬ëŸ¼ í™•ì¸ ë° ìƒì„±
                            if 'cafe_name' not in df_reviews_for_district.columns:
                                if 'ìƒí˜¸ëª…' in df_reviews_for_district.columns:
                                    df_reviews_for_district['cafe_name'] = df_reviews_for_district['ìƒí˜¸ëª…']
                                else:
                                    st.warning("cafe_name ë˜ëŠ” ìƒí˜¸ëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                    df_reviews_for_district = None
                            
                            if df_reviews_for_district is not None:
                                # original_cafe_nameì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ cafe_name ì‚¬ìš©
                                if 'original_cafe_name' in df_reviews_for_district.columns:
                                    cafe_to_district = df_reviews_for_district.groupby('original_cafe_name')['ì‹œêµ°êµ¬ëª…'].first().to_dict()
                                    # top_10_percentì˜ cafe_nameì—ì„œ ìœ„ì¹˜ ì •ë³´ ì œê±°í•˜ì—¬ original_cafe_name ì¶”ì¶œ
                                    top_10_percent['original_cafe_name'] = top_10_percent['cafe_name'].str.split().str[0]
                                    top_10_percent['ì‹œêµ°êµ¬ëª…'] = top_10_percent['original_cafe_name'].map(cafe_to_district)
                                else:
                                    # cafe_nameì—ì„œ ìœ„ì¹˜ ì •ë³´ ì œê±° ì‹œë„ (ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ì²« ë²ˆì§¸ ë¶€ë¶„)
                                    # ë¨¼ì € ì›ë³¸ cafe_nameìœ¼ë¡œ ë§¤í•‘ ì‹œë„
                                    cafe_to_district = df_reviews_for_district.groupby('cafe_name')['ì‹œêµ°êµ¬ëª…'].first().to_dict()
                                    
                                    # ì¹´í˜ëª…ì—ì„œ ìœ„ì¹˜ ì •ë³´ ì œê±° (ì‹œêµ°êµ¬ëª…ê³¼ í–‰ì •ë™ëª…ì´ ì¶”ê°€ëœ ê²½ìš°)
                                    # ì˜ˆ: "íˆ¬ì¸í”Œë ˆì´ìŠ¤ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™" -> "íˆ¬ì¸í”Œë ˆì´ìŠ¤"
                                    top_10_percent['base_cafe_name'] = top_10_percent['cafe_name'].str.split().str[0]
                                    
                                    # ë¨¼ì € ì „ì²´ cafe_nameìœ¼ë¡œ ë§¤í•‘ ì‹œë„, ì—†ìœ¼ë©´ base_cafe_nameìœ¼ë¡œ ì‹œë„
                                    top_10_percent['ì‹œêµ°êµ¬ëª…'] = top_10_percent['cafe_name'].map(cafe_to_district)
                                    # ë§¤í•‘ë˜ì§€ ì•Šì€ ê²½ìš° base_cafe_nameìœ¼ë¡œ ì¬ì‹œë„
                                    missing_mask = top_10_percent['ì‹œêµ°êµ¬ëª…'].isna()
                                    if missing_mask.any():
                                        base_cafe_to_district = df_reviews_for_district.groupby('cafe_name')['ì‹œêµ°êµ¬ëª…'].first().to_dict()
                                        # base_cafe_nameìœ¼ë¡œ ë§¤í•‘ ì‹œë„
                                        for idx in top_10_percent[missing_mask].index:
                                            base_name = top_10_percent.loc[idx, 'base_cafe_name']
                                            # base_nameê³¼ ì¼ì¹˜í•˜ëŠ” cafe_name ì°¾ê¸° (ë¶€ë¶„ ë§¤ì¹­)
                                            matched_district = None
                                            for cafe_name, district in base_cafe_to_district.items():
                                                if cafe_name.startswith(base_name) or base_name in cafe_name:
                                                    matched_district = district
                                                    break
                                            if matched_district:
                                                top_10_percent.loc[idx, 'ì‹œêµ°êµ¬ëª…'] = matched_district
                            
                            # ì‹œêµ°êµ¬ëª…ì´ ìˆëŠ” ì¹´í˜ë§Œ ì‚¬ìš©
                            top_10_percent_with_district = top_10_percent[
                                top_10_percent['ì‹œêµ°êµ¬ëª…'].notna()
                            ]
                            
                            if not top_10_percent_with_district.empty:
                                # í–‰ì •êµ¬ë³„ ì¹´í˜ ìˆ˜ ì§‘ê³„
                                district_counts = top_10_percent_with_district['ì‹œêµ°êµ¬ëª…'].value_counts().sort_values(ascending=True)
                                
                                # ë§‰ëŒ€ ê·¸ë˜í”„
                                df_district = pd.DataFrame({
                                    'í–‰ì •êµ¬': district_counts.index,
                                    'ìƒìœ„ 10% ì¹´í˜ ìˆ˜': district_counts.values
                                })
                                
                                st.bar_chart(df_district.set_index('í–‰ì •êµ¬'), height=400)
                                
                                # ìƒì„¸ í…Œì´ë¸”
                                with st.expander("í–‰ì •êµ¬ë³„ ìƒì„¸ ì •ë³´"):
                                    st.dataframe(
                                        df_district.sort_values('ìƒìœ„ 10% ì¹´í˜ ìˆ˜', ascending=False),
                                        hide_index=True
                                    )
                                
                                st.caption(f"ì´ {len(top_10_percent_with_district)}ê°œ ì¹´í˜ (ì ìˆ˜ ì„ê³„ê°’: {threshold:.3f} ì´ìƒ)")
                                
                                # ìœ„ë„/ê²½ë„ ê°€ì ¸ì˜¤ê¸° ë° ì§€ë„ ì‹œê°í™”
                                if CAFE_INFO_CSV.exists() and HAS_FOLIUM:
                                    try:
                                        # ì¹´í˜ ì •ë³´ CSVì—ì„œ ìœ„ë„/ê²½ë„ ê°€ì ¸ì˜¤ê¸°
                                        df_cafe_info = pd.read_csv(CAFE_INFO_CSV, encoding='utf-8-sig')
                                        
                                        # ìƒí˜¸ëª…, ì‹œêµ°êµ¬ëª…, í–‰ì •ë™ëª…ìœ¼ë¡œ ë§¤ì¹­
                                        # top_10_percent_with_districtì— ìœ„ë„/ê²½ë„ ì¶”ê°€
                                        top_10_percent_with_district['ìœ„ë„'] = None
                                        top_10_percent_with_district['ê²½ë„'] = None
                                        
                                        # ì¹´í˜ëª…ì—ì„œ ìœ„ì¹˜ ì •ë³´ ì œê±° (base_cafe_name ì‚¬ìš©)
                                        if 'base_cafe_name' not in top_10_percent_with_district.columns:
                                            top_10_percent_with_district['base_cafe_name'] = top_10_percent_with_district['cafe_name'].str.split().str[0]
                                        
                                        # í–‰ì •ë™ëª…ë„ ê°€ì ¸ì˜¤ê¸°
                                        if 'df_reviews' in st.session_state and st.session_state.df_reviews is not None:
                                            df_reviews = st.session_state.df_reviews
                                            if 'í–‰ì •ë™ëª…' in df_reviews.columns:
                                                if 'original_cafe_name' in df_reviews.columns:
                                                    cafe_to_dong = df_reviews.groupby('original_cafe_name')['í–‰ì •ë™ëª…'].first().to_dict()
                                                    top_10_percent_with_district['í–‰ì •ë™ëª…'] = top_10_percent_with_district.get('original_cafe_name', top_10_percent_with_district['base_cafe_name']).map(cafe_to_dong)
                                                else:
                                                    cafe_to_dong = df_reviews.groupby('cafe_name')['í–‰ì •ë™ëª…'].first().to_dict()
                                                    top_10_percent_with_district['í–‰ì •ë™ëª…'] = top_10_percent_with_district['cafe_name'].map(cafe_to_dong)
                                        
                                        # ì¹´í˜ ì •ë³´ì™€ ë§¤ì¹­
                                        for idx, row in top_10_percent_with_district.iterrows():
                                            cafe_name = row.get('base_cafe_name', row['cafe_name'].split()[0])
                                            district = row['ì‹œêµ°êµ¬ëª…']
                                            dong = row.get('í–‰ì •ë™ëª…', None)
                                            
                                            matched = None
                                            
                                            # ë§¤ì¹­ ìš°ì„ ìˆœìœ„:
                                            # 1. ì •í™•í•œ ìƒí˜¸ëª… ì¼ì¹˜ + ì‹œêµ°êµ¬ëª… + í–‰ì •ë™ëª…
                                            # 2. ì •í™•í•œ ìƒí˜¸ëª… ì¼ì¹˜ + ì‹œêµ°êµ¬ëª…
                                            # 3. ìƒí˜¸ëª…ì´ cafe_nameìœ¼ë¡œ ì‹œì‘ + ì‹œêµ°êµ¬ëª… + í–‰ì •ë™ëª…
                                            # 4. ìƒí˜¸ëª…ì´ cafe_nameìœ¼ë¡œ ì‹œì‘ + ì‹œêµ°êµ¬ëª…
                                            
                                            if dong and pd.notna(dong):
                                                # 1ìˆœìœ„: ì •í™•í•œ ì¼ì¹˜ + ì‹œêµ°êµ¬ëª… + í–‰ì •ë™ëª…
                                                matched = df_cafe_info[
                                                    (df_cafe_info['ìƒí˜¸ëª…'] == cafe_name) &
                                                    (df_cafe_info['ì‹œêµ°êµ¬ëª…'] == district) &
                                                    (df_cafe_info['í–‰ì •ë™ëª…'] == dong)
                                                ]
                                                
                                                if matched.empty:
                                                    # 2ìˆœìœ„: ìƒí˜¸ëª…ì´ cafe_nameìœ¼ë¡œ ì‹œì‘ + ì‹œêµ°êµ¬ëª… + í–‰ì •ë™ëª…
                                                    matched = df_cafe_info[
                                                        (df_cafe_info['ìƒí˜¸ëª…'].str.startswith(cafe_name, na=False)) &
                                                        (df_cafe_info['ì‹œêµ°êµ¬ëª…'] == district) &
                                                        (df_cafe_info['í–‰ì •ë™ëª…'] == dong)
                                                    ]
                                            else:
                                                # í–‰ì •ë™ëª…ì´ ì—†ìœ¼ë©´ ì‹œêµ°êµ¬ëª…ë§Œìœ¼ë¡œ ë§¤ì¹­
                                                # 1ìˆœìœ„: ì •í™•í•œ ì¼ì¹˜ + ì‹œêµ°êµ¬ëª…
                                                matched = df_cafe_info[
                                                    (df_cafe_info['ìƒí˜¸ëª…'] == cafe_name) &
                                                    (df_cafe_info['ì‹œêµ°êµ¬ëª…'] == district)
                                                ]
                                                
                                                if matched.empty:
                                                    # 2ìˆœìœ„: ìƒí˜¸ëª…ì´ cafe_nameìœ¼ë¡œ ì‹œì‘ + ì‹œêµ°êµ¬ëª…
                                                    matched = df_cafe_info[
                                                        (df_cafe_info['ìƒí˜¸ëª…'].str.startswith(cafe_name, na=False)) &
                                                        (df_cafe_info['ì‹œêµ°êµ¬ëª…'] == district)
                                                    ]
                                            
                                            if not matched.empty:
                                                # ì²« ë²ˆì§¸ ë§¤ì¹­ ì‚¬ìš©
                                                top_10_percent_with_district.loc[idx, 'ìœ„ë„'] = matched.iloc[0]['ìœ„ë„']
                                                top_10_percent_with_district.loc[idx, 'ê²½ë„'] = matched.iloc[0]['ê²½ë„']
                                        
                                        # ìœ„ë„/ê²½ë„ê°€ ìˆëŠ” ì¹´í˜ë§Œ í•„í„°ë§
                                        cafes_with_location = top_10_percent_with_district[
                                            top_10_percent_with_district['ìœ„ë„'].notna() & 
                                            top_10_percent_with_district['ê²½ë„'].notna()
                                        ]
                                        
                                        if not cafes_with_location.empty:
                                            st.markdown("##### ì§€ë„ ì‹œê°í™”")
                                            
                                            # ì„œìš¸ ì¤‘ì‹¬ ì¢Œí‘œ
                                            seoul_center = [37.5665, 126.9780]
                                            
                                            # Folium ì§€ë„ ìƒì„±
                                            m = folium.Map(
                                                location=seoul_center,
                                                zoom_start=11,
                                                tiles='OpenStreetMap'
                                            )
                                            
                                            # ë§ˆì»¤ ì¶”ê°€
                                            for idx, row in cafes_with_location.iterrows():
                                                lat = float(row['ìœ„ë„'])
                                                lng = float(row['ê²½ë„'])
                                                cafe_name = row['cafe_name']
                                                score = row[factor_score_col]
                                                
                                                # íŒì—… ì •ë³´
                                                popup_html = f"""
                                                <div style="font-family: Arial; min-width: 150px;">
                                                    <b>{cafe_name}</b><br>
                                                    {factor} ì ìˆ˜: {score:.3f}<br>
                                                    {row.get('ì‹œêµ°êµ¬ëª…', 'N/A')} {row.get('í–‰ì •ë™ëª…', '')}
                                                </div>
                                                """
                                                
                                                folium.Marker(
                                                    location=[lat, lng],
                                                    popup=folium.Popup(popup_html, max_width=300),
                                                    tooltip=f"{cafe_name} ({score:.3f})",
                                                    icon=folium.Icon(color='red', icon='info-sign')
                                                ).add_to(m)
                                            
                                            # ì§€ë„ í‘œì‹œ
                                            st_folium(m, width=700, height=500)
                                            st.caption(f"ì§€ë„ì— í‘œì‹œëœ ì¹´í˜: {len(cafes_with_location)}ê°œ / ì´ {len(top_10_percent_with_district)}ê°œ")
                                        else:
                                            st.info("ìœ„ë„/ê²½ë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ì¹´í˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                    except Exception as e:
                                        st.warning(f"ì§€ë„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                                elif not HAS_FOLIUM:
                                    st.info("ì§€ë„ ì‹œê°í™”ë¥¼ ìœ„í•´ foliumê³¼ streamlit-folium íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                            else:
                                st.info("ì‹œêµ°êµ¬ëª… ì •ë³´ê°€ ìˆëŠ” ì¹´í˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.info("ë¦¬ë·° ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("ìœ íš¨í•œ ì ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info(f"'{factor_score_col}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ì¥ì†Œì„± ì ìˆ˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¥ì†Œì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”.")


def _display_cafe_reviews(selected_cafe):
    """ì¹´í˜ ë¦¬ë·° í‘œì‹œ í—¬í¼ í•¨ìˆ˜"""
    st.subheader("ğŸ“ í•´ë‹¹ ì¹´í˜ ë¦¬ë·°")
    
    # ë¦¬ë·° ë°ì´í„° ë¡œë“œ
    # configì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (ë°°í¬ í™˜ê²½ í˜¸í™˜ì„±)
    from modules.config import GOOGLE_REVIEW_SAMPLE_CSV
    review_file_path = GOOGLE_REVIEW_SAMPLE_CSV
    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not review_file_path.exists():
        st.warning(f"âš ï¸ ë¦¬ë·° ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {review_file_path}")
        st.info("ğŸ’¡ ë°°í¬ í™˜ê²½ì—ì„œëŠ” íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        return
    
    try:
        # ë¦¬ë·° ë°ì´í„° ë¡œë“œ (ìºì‹œ ì‚¬ìš©)
        @st.cache_data
        def load_reviews_for_cafe():
            df_reviews = pd.read_csv(review_file_path, encoding='utf-8-sig')
            return df_reviews
        
        df_all_reviews = load_reviews_for_cafe()
        
        # ì¹´í˜ëª…ìœ¼ë¡œ í•„í„°ë§ (ë¶€ë¶„ ë§¤ì¹­ë„ ì‹œë„)
        # selected_cafeì—ì„œ ìœ„ì¹˜ ì •ë³´ ì œê±° ì‹œë„ (ì˜ˆ: "ìŠ¤íƒ€ë²…ìŠ¤ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™" -> "ìŠ¤íƒ€ë²…ìŠ¤")
        base_cafe_name = selected_cafe.split()[0] if selected_cafe else ""
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í˜ëª… ì»¬ëŸ¼ í™•ì¸
        cafe_name_col = None
        if 'cafe_name' in df_all_reviews.columns:
            cafe_name_col = 'cafe_name'
        elif 'ìƒí˜¸ëª…' in df_all_reviews.columns:
            cafe_name_col = 'ìƒí˜¸ëª…'
        
        cafe_reviews = pd.DataFrame()  # ë¹ˆ DataFrameìœ¼ë¡œ ì´ˆê¸°í™”
        
        if cafe_name_col:
            # ì •í™•í•œ ë§¤ì¹­ ì‹œë„ (ì „ì²´ ì¹´í˜ëª…)
            cafe_reviews = df_all_reviews[df_all_reviews[cafe_name_col] == selected_cafe].copy()
            
            # ì •í™•í•œ ë§¤ì¹­ì´ ì—†ìœ¼ë©´ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
            if cafe_reviews.empty and base_cafe_name:
                # cafe_nameì´ base_cafe_nameìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
                cafe_reviews = df_all_reviews[
                    df_all_reviews[cafe_name_col].str.startswith(base_cafe_name, na=False)
                ].copy()
            
            # ì—¬ì „íˆ ì—†ìœ¼ë©´ ìƒí˜¸ëª…ìœ¼ë¡œ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
            if cafe_reviews.empty and base_cafe_name:
                if 'ìƒí˜¸ëª…' in df_all_reviews.columns:
                    cafe_reviews = df_all_reviews[
                        df_all_reviews['ìƒí˜¸ëª…'].str.contains(base_cafe_name, na=False, case=False)
                    ].copy()
        else:
            st.warning("ì¹´í˜ëª… ì»¬ëŸ¼(cafe_name ë˜ëŠ” ìƒí˜¸ëª…)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        if not cafe_reviews.empty:
            # ë¦¬ë·° ìˆ˜ í‘œì‹œ
            st.info(f"ì´ {len(cafe_reviews)}ê°œì˜ ë¦¬ë·°ê°€ ìˆìŠµë‹ˆë‹¤.")
            
            # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
            display_cols = []
            if 'ë¦¬ë·°' in cafe_reviews.columns:
                display_cols.append('ë¦¬ë·°')
            elif 'review_text' in cafe_reviews.columns:
                display_cols.append('review_text')
            
            if 'í‰ì ' in cafe_reviews.columns:
                display_cols.insert(0, 'í‰ì ')
            elif 'rating' in cafe_reviews.columns:
                display_cols.insert(0, 'rating')
            
            if 'ì‹œêµ°êµ¬ëª…' in cafe_reviews.columns:
                display_cols.insert(0, 'ì‹œêµ°êµ¬ëª…')
            if 'í–‰ì •ë™ëª…' in cafe_reviews.columns:
                display_cols.insert(0, 'í–‰ì •ë™ëª…')
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ í•„í„°ë§
            available_cols = [col for col in display_cols if col in cafe_reviews.columns]
            
            if available_cols:
                # ë¦¬ë·° í‘œì‹œ (ìµœëŒ€ 100ê°œ)
                max_reviews = min(100, len(cafe_reviews))
                st.dataframe(
                    cafe_reviews[available_cols].head(max_reviews),
                    hide_index=True,
                    **get_dataframe_width_param()
                )
                
                if len(cafe_reviews) > max_reviews:
                    st.caption(f"ìƒìœ„ {max_reviews}ê°œ ë¦¬ë·°ë§Œ í‘œì‹œë©ë‹ˆë‹¤. (ì „ì²´ {len(cafe_reviews)}ê°œ)")
            else:
                st.warning("í‘œì‹œí•  ìˆ˜ ìˆëŠ” ë¦¬ë·° ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning(f"'{selected_cafe}'ì— í•´ë‹¹í•˜ëŠ” ë¦¬ë·°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ íŒ: ì¹´í˜ëª…ì´ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ë³¸ ë¦¬ë·° ë°ì´í„°ì˜ ì¹´í˜ëª… í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                
    except Exception as e:
        st.error(f"ë¦¬ë·° ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        st.code(traceback.format_exc())


def render_cafe_factor_analysis():
    """ì¹´í˜ë³„ ìš”ì¸ ì ìˆ˜ ë¶„ì„ íƒ­ ë Œë”ë§"""
    st.header("ì¹´í˜ë³„ ìš”ì¸ ì ìˆ˜ ë¶„ì„")
    
    # CSV íŒŒì¼ ê²½ë¡œ
    csv_path = Path(__file__).resolve().parent.parent / "placeness_final_research_metrics (3).csv"
    
    if not csv_path.exists():
        st.error(f"âš ï¸ ê²°ê³¼ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        st.info("placeness_final_research_metrics (3).csv íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # CSV íŒŒì¼ ë¡œë“œ
    try:
        df_metrics = pd.read_csv(csv_path, encoding='utf-8-sig')
    except Exception as e:
        st.error(f"CSV íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return
    
    if df_metrics.empty:
        st.warning("ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¹´í˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    cafe_list = sorted(df_metrics['cafe_name'].unique().tolist())
    
    if not cafe_list:
        st.warning("ì¹´í˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¹´í˜ ì„ íƒ
    selected_cafe = st.selectbox(
        "ì¹´í˜ ì„ íƒ",
        options=cafe_list,
        key="cafe_factor_analysis_select",
        help="ë¶„ì„í•  ì¹´í˜ë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )
    
    if not selected_cafe:
        return
    
    # ì„ íƒí•œ ì¹´í˜ì˜ ë°ì´í„° ì¶”ì¶œ
    cafe_data = df_metrics[df_metrics['cafe_name'] == selected_cafe].iloc[0]
    
    st.markdown("---")
    
    # ì¢…í•© ì ìˆ˜ í‘œì‹œ
    col1, col2, col3 = st.columns(3)
    with col1:
        mu_score = cafe_data.get('ì¢…í•©_ì¥ì†Œì„±_ì ìˆ˜_Mu', 0)
        st.metric("ì¢…í•© ì¥ì†Œì„± ì ìˆ˜ (Î¼)", f"{mu_score:.3f}" if pd.notna(mu_score) else "N/A")
    with col2:
        sigma_score = cafe_data.get('ìš”ì¸_ì ìˆ˜_í‘œì¤€í¸ì°¨_Sigma', 0)
        st.metric("í‘œì¤€í¸ì°¨ (Ïƒ)", f"{sigma_score:.3f}" if pd.notna(sigma_score) else "N/A")
    with col3:
        summary = cafe_data.get('Final_PlaceScore_Summary', 'N/A')
        st.metric("ìš”ì•½", summary if pd.notna(summary) else "N/A")
    
    st.markdown("---")
    
    # ìš”ì¸ë³„ ì ìˆ˜ ì¶”ì¶œ (calc ì»¬ëŸ¼ ì‚¬ìš©)
    factor_names = list(ALL_FACTORS.keys())
    factor_scores = {}
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ ëª©ë¡ í™•ì¸
    available_cols = cafe_data.index.tolist()
    
    for factor in factor_names:
        score = None
        
        # calc ì»¬ëŸ¼ ìš°ì„  ì‚¬ìš©
        calc_col = f'ì ìˆ˜_{factor}_calc'
        if calc_col in available_cols:
            score = cafe_data[calc_col]
        else:
            # ì¼ë°˜ ì»¬ëŸ¼ ì‚¬ìš©
            normal_col = f'ì ìˆ˜_{factor}'
            if normal_col in available_cols:
                score = cafe_data[normal_col]
        
        # ì ìˆ˜ ì²˜ë¦¬ (0.5ëŠ” ê¸°ë³¸ê°’ì´ì§€ë§Œ ìœ íš¨í•œ ë°ì´í„°ë¡œ ê°„ì£¼)
        if pd.notna(score):
            try:
                score_val = float(score)
                factor_scores[factor] = score_val
            except (ValueError, TypeError):
                factor_scores[factor] = None
        else:
            factor_scores[factor] = None
    
    # ìš”ì¸ë³„ ì ìˆ˜ ê·¸ë˜í”„ (ë°©ì‚¬í˜• ì°¨íŠ¸)
    st.subheader("ğŸ“ˆ ìš”ì¸ë³„ ì ìˆ˜ ê·¸ë˜í”„")
    
    # ë°ì´í„° ì¤€ë¹„ (Noneì´ ì•„ë‹Œ ëª¨ë“  ì ìˆ˜ í¬í•¨, 0.5ë„ í¬í•¨)
    valid_factors = {k: v for k, v in factor_scores.items() if v is not None}
    
    if valid_factors:
        # ìš”ì¸ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        factor_categories = {
            "ë¬¼ë¦¬ì  íŠ¹ì„±": ["ì‹¬ë¯¸ì„±", "í˜•íƒœì„±", "ê°ê°ì  ê²½í—˜", "ì ‘ê·¼ì„±", "ì¾Œì ì„±"],
            "í™œë™ì  íŠ¹ì„±": ["í™œë™ì„±", "ì‚¬íšŒì„±", "ì°¸ì—¬ì„±"],
            "ì˜ë¯¸ì  íŠ¹ì„±": ["ê³ ìœ ì„±", "ê¸°ì–µ/ê²½í—˜", "ì§€ì—­ ì •ì²´ì„±"]
        }
        
        if HAS_PLOTLY:
            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ íƒ­ ìƒì„±
            tabs = st.tabs(["ì „ì²´ ìš”ì¸", "ë¬¼ë¦¬ì  íŠ¹ì„±", "í™œë™ì  íŠ¹ì„±", "ì˜ë¯¸ì  íŠ¹ì„±"])
            
            def create_radar_chart(factors_dict, title, max_value=1.0):
                """ë°©ì‚¬í˜• ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜"""
                theta = list(factors_dict.keys())
                r = list(factors_dict.values())
                
                # ì°¨íŠ¸ë¥¼ ë‹«ê¸° ìœ„í•´ ì²« ë²ˆì§¸ ê°’ì„ ë§ˆì§€ë§‰ì— ì¶”ê°€
                theta_closed = theta + [theta[0]]
                r_closed = r + [r[0]]
                
                fig = go.Figure()
                
                fig.add_trace(go.Scatterpolar(
                    r=r_closed,
                    theta=theta_closed,
                    fill='toself',
                    name='ìš”ì¸ ì ìˆ˜',
                    line=dict(color='rgb(32, 201, 151)', width=2),
                    fillcolor='rgba(32, 201, 151, 0.25)',
                    hovertemplate='<b>%{theta}</b><br>ì ìˆ˜: %{r:.3f}<extra></extra>'
                ))
                
                fig.update_layout(
                    polar=dict(
                        radialaxis=dict(
                            visible=True,
                            range=[0, max_value],
                            tickmode='linear',
                            tick0=0,
                            dtick=0.2,
                            tickfont=dict(size=10),
                            gridcolor='rgba(200, 200, 200, 0.3)'
                        ),
                        angularaxis=dict(
                            rotation=90,
                            direction='counterclockwise',
                            tickfont=dict(size=11)
                        )
                    ),
                    title=dict(
                        text=title,
                        x=0.5,
                        font=dict(size=16, color='#1f77b4')
                    ),
                    height=500,
                    showlegend=False,
                    paper_bgcolor='white',
                    plot_bgcolor='white'
                )
                
                return fig
            
            with tabs[0]:
                # ë°©ì‚¬í˜• ì°¨íŠ¸ì™€ ìƒì„¸ ì ìˆ˜ë¥¼ ë‚˜ë€íˆ ë°°ì¹˜
                col_left, col_right = st.columns([1, 1])
                
                with col_left:
                    # ì „ì²´ ìš”ì¸ ë°©ì‚¬í˜• ì°¨íŠ¸
                    fig_all = create_radar_chart(valid_factors, f"{selected_cafe}")
                    st.plotly_chart(fig_all, use_container_width=True)
                
                with col_right:
                    # ìƒì„¸ ì ìˆ˜ ë³´ê¸°
                    st.subheader("ìƒì„¸ ì ìˆ˜ ë³´ê¸°")
                    df_detail = pd.DataFrame({
                        'ìš”ì¸': list(valid_factors.keys()),
                        'ì ìˆ˜': [f"{v:.3f}" for v in valid_factors.values()]
                    })
                    st.dataframe(df_detail, hide_index=True, **get_dataframe_width_param())
            
            # ì¹´í…Œê³ ë¦¬ë³„ íƒ­
            for tab_idx, (category, factors) in enumerate(factor_categories.items(), 1):
                with tabs[tab_idx]:
                    category_scores = {k: v for k, v in valid_factors.items() if k in factors}
                    
                    if category_scores:
                        # ì¹´í…Œê³ ë¦¬ë³„ ë°©ì‚¬í˜• ì°¨íŠ¸
                        fig_category = create_radar_chart(
                            category_scores, 
                            f"{selected_cafe} - {category}",
                            max_value=1.0
                        )
                        st.plotly_chart(fig_category, use_container_width=True)
                        
                        # í‰ê·  ì ìˆ˜
                        avg_score = sum(category_scores.values()) / len(category_scores)
                        st.metric(f"{category} í‰ê·  ì ìˆ˜", f"{avg_score:.3f}")
                    else:
                        st.info(f"{category} ê´€ë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # plotlyê°€ ì—†ìœ¼ë©´ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ëŒ€ì²´
            st.warning("âš ï¸ plotlyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ í‘œì‹œë©ë‹ˆë‹¤. ë°©ì‚¬í˜• ì°¨íŠ¸ë¥¼ ë³´ë ¤ë©´ `pip install plotly`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            
            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ íƒ­ ìƒì„±
            tabs = st.tabs(["ì „ì²´ ìš”ì¸", "ë¬¼ë¦¬ì  íŠ¹ì„±", "í™œë™ì  íŠ¹ì„±", "ì˜ë¯¸ì  íŠ¹ì„±"])
            
            with tabs[0]:
                # ë§‰ëŒ€ ê·¸ë˜í”„ì™€ ìƒì„¸ ì ìˆ˜ë¥¼ ë‚˜ë€íˆ ë°°ì¹˜
                col_left, col_right = st.columns([1, 1])
                
                with col_left:
                    # ì „ì²´ ìš”ì¸ ë§‰ëŒ€ ê·¸ë˜í”„
                    df_chart = pd.DataFrame({
                        'ìš”ì¸': list(valid_factors.keys()),
                        'ì ìˆ˜': list(valid_factors.values())
                    })
                    df_chart = df_chart.sort_values('ì ìˆ˜', ascending=True)
                    
                    st.bar_chart(df_chart.set_index('ìš”ì¸'), height=400)
                
                with col_right:
                    # ìƒì„¸ ì ìˆ˜ ë³´ê¸°
                    st.subheader("ìƒì„¸ ì ìˆ˜ ë³´ê¸°")
                    df_detail = pd.DataFrame({
                        'ìš”ì¸': list(valid_factors.keys()),
                        'ì ìˆ˜': [f"{v:.3f}" for v in valid_factors.values()]
                    })
                    st.dataframe(df_detail, hide_index=True, **get_dataframe_width_param())
            
            # ì¹´í…Œê³ ë¦¬ë³„ íƒ­
            for tab_idx, (category, factors) in enumerate(factor_categories.items(), 1):
                with tabs[tab_idx]:
                    category_scores = {k: v for k, v in valid_factors.items() if k in factors}
                    
                    if category_scores:
                        df_category = pd.DataFrame({
                            'ìš”ì¸': list(category_scores.keys()),
                            'ì ìˆ˜': list(category_scores.values())
                        })
                        df_category = df_category.sort_values('ì ìˆ˜', ascending=True)
                        
                        st.bar_chart(df_category.set_index('ìš”ì¸'), height=300)
                        
                        # í‰ê·  ì ìˆ˜
                        avg_score = sum(category_scores.values()) / len(category_scores)
                        st.metric(f"{category} í‰ê·  ì ìˆ˜", f"{avg_score:.3f}")
                    else:
                        st.info(f"{category} ê´€ë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("í‘œì‹œí•  ìš”ì¸ ì ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ê°•ì /ì•½ì  ìš”ì¸ í‘œì‹œ
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("(+)ê°•ì  ìš”ì¸")
        strength_factors = cafe_data.get('ê°•ì _ìš”ì¸(+df+)', 'N/A')
        if pd.notna(strength_factors) and strength_factors != 'N/A':
            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ìš”ì¸ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if isinstance(strength_factors, str):
                strength_list = [f.strip() for f in strength_factors.split(',') if f.strip()]
            else:
                strength_list = []
            
            if strength_list:
                for factor in strength_list:
                    score = valid_factors.get(factor, None)
                    if score is not None:
                        st.success(f"**{factor}**: {score:.3f}")
                    else:
                        st.success(f"**{factor}**")
            else:
                st.info("ê°•ì  ìš”ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ê°•ì  ìš”ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    with col2:
        st.subheader("(-)ì•½ì  ìš”ì¸")
        weakness_factors = cafe_data.get('ì•½ì _ìš”ì¸(-df-)', 'N/A')
        if pd.notna(weakness_factors) and weakness_factors != 'N/A':
            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ìš”ì¸ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if isinstance(weakness_factors, str):
                weakness_list = [f.strip() for f in weakness_factors.split(',') if f.strip()]
            else:
                weakness_list = []
            
            if weakness_list:
                for factor in weakness_list:
                    score = valid_factors.get(factor, None)
                    if score is not None:
                        st.error(f"**{factor}**: {score:.3f}")
                    else:
                        st.error(f"**{factor}**")
            else:
                st.info("ì•½ì  ìš”ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì•½ì  ìš”ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ê°•ì /ì•½ì  ìš”ì¸ ì•„ë˜ì— ë¦¬ë·° í‘œì‹œ
    st.markdown("---")
    _display_cafe_reviews(selected_cafe)
    
    st.markdown("---")
    
    # ì „ì²´ ë°ì´í„° í‘œì‹œ (í™•ì¥ ê°€ëŠ¥)
    with st.expander("ğŸ“‹ ì „ì²´ ë°ì´í„° ë³´ê¸°"):
        # _calcë¡œ ëë‚˜ëŠ” ì»¬ëŸ¼ ì œì™¸
        filtered_data = cafe_data[~cafe_data.index.str.endswith('_calc', na=False)]
        st.dataframe(filtered_data.to_frame().T, **get_dataframe_width_param())


def render_cafe_recommendation():
    """ì¹´í˜ ì¶”ì²œ íƒ­ ë Œë”ë§"""
    # íŒŒìŠ¤í…”í†¤ primary ë²„íŠ¼ ìŠ¤íƒ€ì¼ ì ìš©
    st.markdown("""
    <style>
    /* Primary ë²„íŠ¼ - íŒŒìŠ¤í…”í†¤ í•˜ëŠ˜ìƒ‰ */
    div[data-testid="stButton"] > button[kind="primary"] {
        background-color: #BEE3F8 !important; /* ë¶€ë“œëŸ¬ìš´ íŒŒìš°ë” ë¸”ë£¨ */
        color: #2C5282 !important; /* í…ìŠ¤íŠ¸ëŠ” ì§™ì€ ë„¤ì´ë¹„ë¡œ ê°€ë…ì„± í™•ë³´ */
        border: none !important;
        border-radius: 12px !important; /* ë‘¥ê¸€ê²Œ ì²˜ë¦¬í•˜ë©´ ë” ê·€ì—¬ì›€ */
        font-weight: 600 !important;
        padding: 0.5rem 1rem !important;
        transition: all 0.3s ease !important;
    }

    div[data-testid="stButton"] > button[kind="primary"]:hover {
        background-color: #90CDF4 !important; /* í˜¸ë²„ ì‹œ ì¡°ê¸ˆ ë” ì§„í•œ í•˜ëŠ˜ìƒ‰ */
        transform: translateY(-2px) !important;
        box-shadow: 0 4px 12px rgba(144, 205, 244, 0.4) !important;
    }
    
    /* Multiselect ì„ íƒëœ íƒœê·¸ - íŒŒìŠ¤í…”í†¤ ë…¸ë€ìƒ‰ */
    div[data-baseweb="select"] p[data-baseweb="tag"],
    div[data-baseweb="select"] span[data-baseweb="tag"],
    div[data-baseweb="select"] div[data-baseweb="tag"],
    div[data-testid="stMultiSelect"] p[data-baseweb="tag"],
    div[data-testid="stMultiSelect"] span[data-baseweb="tag"],
    div[data-testid="stMultiSelect"] div[data-baseweb="tag"] {
        background-color: #FEF3C7 !important; /* ë¶€ë“œëŸ¬ìš´ íŒŒìŠ¤í…”í†¤ ë…¸ë€ìƒ‰ */
        color: #92400E !important; /* í…ìŠ¤íŠ¸ëŠ” ì§™ì€ ê°ˆìƒ‰ìœ¼ë¡œ ê°€ë…ì„± í™•ë³´ */
        border: none !important;
        border-radius: 8px !important;
        font-weight: 500 !important;
    }
    
    /* Multiselect íƒœê·¸ì˜ X ë²„íŠ¼ */
    div[data-baseweb="select"] button[aria-label],
    div[data-testid="stMultiSelect"] button[aria-label] {
        color: #92400E !important;
    }
    
    /* Multiselect íƒœê·¸ í˜¸ë²„ íš¨ê³¼ */
    div[data-baseweb="select"] p[data-baseweb="tag"]:hover,
    div[data-baseweb="select"] span[data-baseweb="tag"]:hover,
    div[data-baseweb="select"] div[data-baseweb="tag"]:hover,
    div[data-testid="stMultiSelect"] p[data-baseweb="tag"]:hover,
    div[data-testid="stMultiSelect"] span[data-baseweb="tag"]:hover,
    div[data-testid="stMultiSelect"] div[data-baseweb="tag"]:hover {
        background-color: #FDE68A !important; /* í˜¸ë²„ ì‹œ ì¡°ê¸ˆ ë” ì§„í•œ ë…¸ë€ìƒ‰ */
    }
    </style>
    """, unsafe_allow_html=True)

    st.caption("ì„ í˜¸í•˜ëŠ” íŠ¹ì„±ì— ë§ëŠ” ì¹´í˜ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤.")
    
    # CSV íŒŒì¼ ê²½ë¡œ
    csv_path = Path(__file__).resolve().parent.parent / "placeness_final_research_metrics (3).csv"
    
    if not csv_path.exists():
        st.error(f"âš ï¸ ê²°ê³¼ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        st.info("placeness_final_research_metrics (3).csv íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # CSV íŒŒì¼ ë¡œë“œ
    try:
        df_metrics = pd.read_csv(csv_path, encoding='utf-8-sig')
    except Exception as e:
        st.error(f"CSV íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return
    
    if df_metrics.empty:
        st.warning("ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í–‰ì •êµ¬ íŒŒì‹± (cafe_nameì—ì„œ ì¶”ì¶œ)
    # ì„œìš¸ì‹œ ì‹¤ì œ í–‰ì •êµ¬ ëª©ë¡
    SEOUL_DISTRICTS = [
        "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ìš©ì‚°êµ¬", "ì„±ë™êµ¬", "ê´‘ì§„êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ì¤‘ë‘êµ¬",
        "ì„±ë¶êµ¬", "ê°•ë¶êµ¬", "ë„ë´‰êµ¬", "ë…¸ì›êµ¬", "ì€í‰êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ë§ˆí¬êµ¬",
        "ì–‘ì²œêµ¬", "ê°•ì„œêµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬", "ì˜ë“±í¬êµ¬", "ë™ì‘êµ¬", "ê´€ì•…êµ¬",
        "ì„œì´ˆêµ¬", "ê°•ë‚¨êµ¬", "ì†¡íŒŒêµ¬", "ê°•ë™êµ¬"
    ]
    
    def parse_district(cafe_name):
        """ì¹´í˜ëª…ì—ì„œ ì‹¤ì œ í–‰ì •êµ¬ë§Œ ì¶”ì¶œ"""
        if pd.isna(cafe_name):
            return None
        parts = str(cafe_name).split()
        for part in parts:
            # ì‹¤ì œ ì„œìš¸ì‹œ í–‰ì •êµ¬ ëª©ë¡ì— ìˆëŠ” ê²ƒë§Œ ë°˜í™˜
            if part in SEOUL_DISTRICTS:
                return part
        return None
    
    df_metrics['í–‰ì •êµ¬'] = df_metrics['cafe_name'].apply(parse_district)
    available_districts = sorted([d for d in df_metrics['í–‰ì •êµ¬'].dropna().unique() if d])
    
    # 1. í–‰ì •êµ¬ ì„ íƒ
    st.subheader("ğŸ“ ì§€ì—­ ì„ íƒ")
    selected_districts = st.multiselect(
        "ì›í•˜ëŠ” í–‰ì •êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš” (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥, ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ì§€ì—­)",
        options=available_districts,
        default=[],
        key="recommendation_districts"
    )
    
    # í•„í„°ë§
    if selected_districts:
        df_filtered = df_metrics[df_metrics['í–‰ì •êµ¬'].isin(selected_districts)].copy()
    else:
        df_filtered = df_metrics.copy()
    
    if df_filtered.empty:
        st.warning("ì„ íƒí•œ ì§€ì—­ì— í•´ë‹¹í•˜ëŠ” ì¹´í˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.markdown("---")
    
    # 2. ì„ í˜¸ íŠ¹ì„± ì„ íƒ (ê°€ë¡œ ë²„íŠ¼ ë°°ì¹˜)
    st.subheader("ì„ í˜¸í•˜ëŠ” íŠ¹ì„± ì„ íƒ")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•ˆì „í•˜ê²Œ)
    if 'recommendation_preference_type' not in st.session_state:
        st.session_state.recommendation_preference_type = None
    if 'recommendation_selected_details' not in st.session_state:
        st.session_state.recommendation_selected_details = []
    
    # preference_typeì„ ì„¸ì…˜ ìƒíƒœì—ì„œ ì½ê¸° (í•­ìƒ ìµœì‹  ìƒíƒœ ë³´ì¥)
    preference_type = st.session_state.get('recommendation_preference_type', None)
    
    # ê°€ë¡œë¡œ 3ê°œ ë²„íŠ¼ ë°°ì¹˜
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ›ï¸ ë¬¼ë¦¬ì  íŠ¹ì„±", 
                    use_container_width=True,
                    type="primary" if preference_type == "ë¬¼ë¦¬ì  íŠ¹ì„±" else "secondary",
                    key="btn_physical"):
            st.session_state.recommendation_preference_type = "ë¬¼ë¦¬ì  íŠ¹ì„±"
            st.session_state.recommendation_selected_details = []
            st.rerun()
    
    with col2:
        if st.button("ğŸ­ í™œë™ì  íŠ¹ì„±",
                    use_container_width=True,
                    type="primary" if preference_type == "í™œë™ì  íŠ¹ì„±" else "secondary",
                    key="btn_activity"):
            st.session_state.recommendation_preference_type = "í™œë™ì  íŠ¹ì„±"
            st.session_state.recommendation_selected_details = []
            st.rerun()
    
    with col3:
        if st.button("ğŸ’­ ì˜ë¯¸ì  íŠ¹ì„±",
                    use_container_width=True,
                    type="primary" if preference_type == "ì˜ë¯¸ì  íŠ¹ì„±" else "secondary",
                    key="btn_semantic"):
            st.session_state.recommendation_preference_type = "ì˜ë¯¸ì  íŠ¹ì„±"
            st.session_state.recommendation_selected_details = []
            st.rerun()
    
    # 3. ì„¸ë¶€ í•­ëª© ì„ íƒ (ì„ íƒëœ íŠ¹ì„± ì•„ë˜ì— í‘œì‹œ)
    # preference_typeì„ ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸ (ë²„íŠ¼ í´ë¦­ í›„ ìµœì‹  ìƒíƒœ)
    preference_type = st.session_state.get('recommendation_preference_type', None)
    
    if preference_type:
        st.markdown("---")
        st.subheader(f"{preference_type} ì„¸ë¶€ í•­ëª© ì„ íƒ")
        
        detail_options = []
        
        if preference_type == "ë¬¼ë¦¬ì  íŠ¹ì„±":
            detail_options = [
                ("ì‹¬ë¯¸ì„±", "ì¸í…Œë¦¬ì–´ê°€ ì˜ˆìœ ê³³"),
                ("ì¾Œì ì„±", "ì¾Œì í•œ ê³³"),
                ("ì ‘ê·¼ì„±", "ì ‘ê·¼ì´ í¸ë¦¬í•œ ê³³"),
                ("í˜•íƒœì„±", "ê³µê°„ êµ¬ì¡°ê°€ ì¢‹ì€ ê³³"),
                ("ê°ê°ì  ê²½í—˜", "ê°ê°ì ì¸ ê²½í—˜ì„ í•  ìˆ˜ ìˆëŠ” ê³³")
            ]
        elif preference_type == "í™œë™ì  íŠ¹ì„±":
            detail_options = [
                ("ì‚¬íšŒì„±", "ì¹œì ˆí•œ ì„œë¹„ìŠ¤"),
                ("í™œë™ì„±", "ëª¨ì„í•˜ê¸° ì¢‹ì€ ê³³"),
                ("ì°¸ì—¬ì„±", "ì²´í—˜/ì´ë²¤íŠ¸ê°€ ìˆëŠ” ê³³")
            ]
        elif preference_type == "ì˜ë¯¸ì  íŠ¹ì„±":
            detail_options = [
                ("ê³ ìœ ì„±", "ë…íŠ¹í•œ ì»¨ì…‰íŠ¸ê°€ ìˆëŠ” ê³³"),
                ("ê¸°ì–µ/ê²½í—˜", "ê¸°ì–µì— ë‚¨ëŠ” ê²½í—˜ì„ ì œê³µí•˜ëŠ” ê³³"),
                ("ì§€ì—­ ì •ì²´ì„±", "ì§€ì—­ ë¬¸í™”ë¥¼ ë°˜ì˜í•œ ê³³")
            ]
        
        # ì„¸ë¶€ í•­ëª©ì„ ë²„íŠ¼ìœ¼ë¡œ í‘œì‹œ (ìˆ˜í˜•ë„ì²˜ëŸ¼)
        st.markdown("<div style='margin-left: 20px;'>", unsafe_allow_html=True)
        
        # ë²„íŠ¼ì„ ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜ (2ì—´)
        num_cols = 2
        cols = st.columns(num_cols)
        
        for idx, (factor_key, factor_desc) in enumerate(detail_options):
            col_idx = idx % num_cols
            with cols[col_idx]:
                # ì„¸ì…˜ ìƒíƒœì—ì„œ ìµœì‹  ì„ íƒ ìƒíƒœ í™•ì¸
                current_selected = st.session_state.get('recommendation_selected_details', [])
                is_selected = factor_key in current_selected
                button_type = "primary" if is_selected else "secondary"
                
                if st.button(
                    f"âœ“ {factor_desc}" if is_selected else factor_desc,
                    use_container_width=True,
                    type=button_type,
                    key=f"detail_btn_{preference_type}_{factor_key}"
                ):
                    # preference_typeì´ ìœ ì§€ë˜ë„ë¡ ëª…ì‹œì ìœ¼ë¡œ ë³´ì¥
                    st.session_state.recommendation_preference_type = preference_type
                    
                    # ì„¸ì…˜ ìƒíƒœì—ì„œ ìµœì‹  ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    if 'recommendation_selected_details' not in st.session_state:
                        st.session_state.recommendation_selected_details = []
                    
                    # ë¦¬ìŠ¤íŠ¸ ë³µì‚¬ë³¸ìœ¼ë¡œ ì‘ì—… (ì°¸ì¡° ë¬¸ì œ ë°©ì§€)
                    current_list = list(st.session_state.recommendation_selected_details)
                    
                    if is_selected:
                        # ì„ íƒ í•´ì œ
                        if factor_key in current_list:
                            current_list.remove(factor_key)
                    else:
                        # ì„ íƒ ì¶”ê°€
                        if factor_key not in current_list:
                            current_list.append(factor_key)
                    
                    # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                    st.session_state.recommendation_selected_details = current_list
                    st.rerun()
        
        st.markdown("</div>", unsafe_allow_html=True)
        
        selected_details = st.session_state.get('recommendation_selected_details', [])
    else:
        selected_details = []
    
    # 4. ì¶”ì²œ ì‹¤í–‰
    if preference_type:
        st.markdown("---")
        if st.button("ğŸ” ì¶”ì²œ ë°›ê¸°", type="primary", key="recommendation_search", use_container_width=True):
            if not selected_details:
                st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ì˜ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                # ì¶”ì²œ ë¡œì§
                recommendations = _calculate_recommendations(df_filtered, selected_details)
                
                if recommendations.empty:
                    st.warning("ì„ íƒí•œ ì¡°ê±´ì— ë§ëŠ” ì¹´í˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.success(f"âœ… {len(recommendations)}ê°œì˜ ì¹´í˜ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    st.markdown("---")
                    
                    # ìƒìœ„ 3ê°œ ì¶”ì²œ
                    top_3 = recommendations.head(3)
                    
                    for idx, (_, row) in enumerate(top_3.iterrows(), 1):
                        with st.container():
                            col1, col2 = st.columns([3, 1])
                            
                            with col1:
                                st.markdown(f"### {idx}. {row['cafe_name']}")
                                if pd.notna(row.get('í–‰ì •êµ¬')):
                                    st.caption(f"ğŸ“ {row['í–‰ì •êµ¬']}")
                            
                            with col2:
                                mu_score = row.get('ì¢…í•©_ì¥ì†Œì„±_ì ìˆ˜_Mu', 0)
                                if pd.notna(mu_score) and mu_score > 0:
                                    st.metric("ì¢…í•© ì ìˆ˜", f"{mu_score:.3f}")
                                else:
                                    st.metric("ì¢…í•© ì ìˆ˜", "N/A")
                            
                            # ì„ íƒí•œ ì„¸ë¶€ í•­ëª©ë³„ ì ìˆ˜ í‘œì‹œ
                            score_cols = st.columns(len(selected_details))
                            for i, detail in enumerate(selected_details):
                                with score_cols[i]:
                                    score_col = f"ì ìˆ˜_{detail}"
                                    if score_col in row.index:
                                        score = row[score_col]
                                        if pd.notna(score) and score != 0.5:
                                            st.metric(detail, f"{score:.3f}")
                                        else:
                                            st.metric(detail, "N/A")
                                    else:
                                        st.metric(detail, "N/A")
                            
                            st.markdown("---")


def _calculate_recommendations(df: pd.DataFrame, selected_factors: list) -> pd.DataFrame:
    """ì„ íƒí•œ ìš”ì¸ì— ë”°ë¼ ì¹´í˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."""
    # ê° ìš”ì¸ë³„ ì ìˆ˜ ì»¬ëŸ¼ëª…
    factor_score_cols = [f"ì ìˆ˜_{factor}" for factor in selected_factors]
    
    # ìœ íš¨í•œ ì ìˆ˜ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    valid_cols = [col for col in factor_score_cols if col in df.columns]
    
    if not valid_cols:
        return pd.DataFrame()
    
    # ê° ìš”ì¸ë³„ ì ìˆ˜ ê³„ì‚° (0.5ëŠ” ê¸°ë³¸ê°’ì´ë¯€ë¡œ ì œì™¸)
    df_scored = df.copy()
    
    # ì¶”ì²œ ì ìˆ˜ ê³„ì‚°: ì„ íƒí•œ ìš”ì¸ë“¤ì˜ í‰ê·  ì ìˆ˜
    scores = []
    for _, row in df_scored.iterrows():
        factor_scores = []
        for col in valid_cols:
            score = row[col]
            if pd.notna(score) and score != 0.5:  # ê¸°ë³¸ê°’ ì œì™¸
                factor_scores.append(score)
        
        if factor_scores:
            avg_score = sum(factor_scores) / len(factor_scores)
            scores.append(avg_score)
        else:
            scores.append(0)
    
    df_scored['ì¶”ì²œ_ì ìˆ˜'] = scores
    
    # ì¶”ì²œ ì ìˆ˜ê°€ 0ë³´ë‹¤ í° ì¹´í˜ë§Œ í•„í„°ë§
    df_scored = df_scored[df_scored['ì¶”ì²œ_ì ìˆ˜'] > 0].copy()
    
    # ì¶”ì²œ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
    df_scored = df_scored.sort_values('ì¶”ì²œ_ì ìˆ˜', ascending=False)
    
    return df_scored