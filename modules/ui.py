"""
Streamlit UI êµ¬ì„± ëª¨ë“ˆ
"""
import streamlit as st
import pandas as pd
import re
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from pathlib import Path
try:
    import folium
    from streamlit_folium import st_folium
    HAS_FOLIUM = True
except ImportError:
    HAS_FOLIUM = False
from modules.config import ALL_FACTORS, SIMILARITY_THRESHOLD, CAFE_INFO_CSV
from modules.sentiment import run_sentiment_analysis
from modules.score import calculate_place_scores, calculate_final_research_metrics
from modules.preprocess import load_csv_raw, is_numeric_only, is_metadata_only, truncate_text_for_bert
from modules.sentiment import process_sentiment_result

# í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ (ì„ íƒì , ì§€ì—° ì´ˆê¸°í™”)
HAS_KONLPY = False
okt = None

def _init_konlpy():
    """konlpyë¥¼ ì§€ì—° ì´ˆê¸°í™”í•©ë‹ˆë‹¤. Javaê°€ ì—†ìœ¼ë©´ Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global HAS_KONLPY, okt
    if HAS_KONLPY and okt is not None:
        return okt
    
    try:
        from konlpy.tag import Okt
        okt = Okt()
        HAS_KONLPY = True
        return okt
    except (ImportError, Exception) as e:
        HAS_KONLPY = False
        okt = None
        return None


def render_data_preview(file_path, sentiment_pipeline, sentiment_model_name):
    """ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜ ë Œë”ë§"""
    st.markdown("---")
    st.header("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    
    # ì „ì²´ ë°ì´í„° ë¡œë“œ (ë¯¸ë¦¬ë³´ê¸°ìš©, ì›ë³¸ ì»¬ëŸ¼ëª… ìœ ì§€)
    df_preview = load_csv_raw(file_path)
    
    # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸ ë° ì„ íƒ
    required_cols = ['ìƒí˜¸ëª…', 'ì‹œêµ°êµ¬ëª…', 'í–‰ì •ë™ëª…', 'í‰ì ', 'ë¦¬ë·°']
    available_cols = [col for col in required_cols if col in df_preview.columns]
    
    if len(available_cols) == len(required_cols):
        # í–‰ì •êµ¬ë³„ë¡œ ì •ë ¬ (ì‹œêµ°êµ¬ëª…, ìƒí˜¸ëª…, í–‰ì •ë™ëª… ìˆœ)
        df_preview_sorted = df_preview[available_cols].copy()
        df_preview_sorted = df_preview_sorted.sort_values(by=['ì‹œêµ°êµ¬ëª…', 'ìƒí˜¸ëª…', 'í–‰ì •ë™ëª…'], ascending=[True, True, True])
        
        # í‘œë¥¼ í™”ë©´ ì „ì²´ ë„ˆë¹„ë¡œ í‘œì‹œí•˜ê¸° ìœ„í•œ CSS ìŠ¤íƒ€ì¼
        st.markdown("""
<style>
        .stDataFrame {
            width: 100% !important;
        }
        div[data-testid="stDataFrame"] {
            width: 100% !important;
    }
</style>
""", unsafe_allow_html=True)

        st.dataframe(
            df_preview_sorted,
            use_container_width=True,
            hide_index=True
        )
        st.caption(f"ì „ì²´ {len(df_preview_sorted):,}ê°œ ë¦¬ë·° (í–‰ì •êµ¬ë³„ ì •ë ¬)")
        
        # ê°ì„± ë¶„ì„ ì¶”ê°€ ë²„íŠ¼
        st.markdown("---")
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if st.session_state.preview_sentiment_result is not None:
            df_preview_with_sentiment = st.session_state.preview_sentiment_result
            st.success(f"âœ… ê°ì„± ë¶„ì„ ê²°ê³¼ (ì´ {len(df_preview_with_sentiment):,}ê°œ ë¦¬ë·°)")
            
            # ê²°ê³¼ í‘œì‹œ
            st.dataframe(
                df_preview_with_sentiment,
                use_container_width=True,
                hide_index=True,
            )
            
            # í†µê³„ ì •ë³´
            sentiment_labels = df_preview_with_sentiment['ê°ì„±ë¶„ì„'].tolist()
            col1, col2, col3 = st.columns(3)
            with col1:
                positive_count = sentiment_labels.count('ê¸ì •')
                st.metric("ê¸ì • ë¦¬ë·°", f"{positive_count:,}ê°œ ({positive_count/len(sentiment_labels)*100:.1f}%)")
            with col2:
                negative_count = sentiment_labels.count('ë¶€ì •')
                st.metric("ë¶€ì • ë¦¬ë·°", f"{negative_count:,}ê°œ ({negative_count/len(sentiment_labels)*100:.1f}%)")
            with col3:
                neutral_count = sentiment_labels.count('ì¤‘ë¦½')
                if neutral_count > 0:
                    st.metric("ì¤‘ë¦½ ë¦¬ë·°", f"{neutral_count:,}ê°œ ({neutral_count/len(sentiment_labels)*100:.1f}%)")
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            csv = df_preview_with_sentiment.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "ğŸ“¥ ê°ì„± ë¶„ì„ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="google_reviews_with_sentiment.csv",
                mime="text/csv"
            )
            
            # ì¬ì‹¤í–‰ ë²„íŠ¼
            if st.button("ğŸ”„ ê°ì„± ë¶„ì„ ë‹¤ì‹œ ì‹¤í–‰", type="secondary"):
                st.session_state.preview_sentiment_result = None
                st.rerun()
        else:
            # ê°ì„± ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
            if st.button("ğŸ” ê°ì„± ë¶„ì„ ì¶”ê°€ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)", type="secondary"):
                _run_preview_sentiment_analysis(df_preview_sorted, sentiment_pipeline, sentiment_model_name)
    else:
        st.warning(f"í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(df_preview.columns)}")


def _run_preview_sentiment_analysis(df_preview_sorted, sentiment_pipeline, sentiment_model_name):
    """ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜ì˜ ê°ì„± ë¶„ì„ ì‹¤í–‰"""
    with st.spinner(f"ê°ì„± ë¶„ì„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ë·°ë³„ ê°ì„± ë¶„ì„ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
        # ë¦¬ë·° í…ìŠ¤íŠ¸ ë° í‰ì  ì¶”ì¶œ
        review_texts = df_preview_sorted['ë¦¬ë·°'].astype(str).tolist()
        ratings = df_preview_sorted['í‰ì '].astype(float).tolist() if 'í‰ì ' in df_preview_sorted.columns else [None] * len(review_texts)
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        batch_size = 32
        total_batches = (len(review_texts) + batch_size - 1) // batch_size
        
        sentiment_labels = []
        sentiment_scores = []
        
        for batch_idx in range(total_batches):
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, len(review_texts))
            batch_texts = review_texts[start_idx:end_idx]
            batch_ratings = ratings[start_idx:end_idx] if ratings else [None] * len(batch_texts)
            
            progress = (batch_idx + 1) / total_batches
            progress_bar.progress(progress)
            status_text.text(f"ì²˜ë¦¬ ì¤‘: {batch_idx + 1}/{total_batches} ë°°ì¹˜ ({len(batch_texts)}ê°œ ë¦¬ë·°)")
            
            try:
                # ìˆ«ì-only ë¦¬ë·°ì™€ ì¼ë°˜ í…ìŠ¤íŠ¸ ë¦¬ë·° ë¶„ë¦¬
                text_batch = []
                batch_results_map = {}
                
                for idx, text in enumerate(batch_texts):
                    rating = batch_ratings[idx] if idx < len(batch_ratings) else None
                    
                    # ìˆ«ì-only ë¦¬ë·°ëŠ” ë³„ì  ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬
                    if is_numeric_only(text):
                        try:
                            rating_value = float(text)
                            if rating_value >= 4.0:
                                batch_results_map[idx] = ("ê¸ì •", 0.9)
                            elif rating_value >= 3.0:
                                batch_results_map[idx] = ("ì¤‘ë¦½", 0.5)
                            else:
                                batch_results_map[idx] = ("ë¶€ì •", 0.1)
                        except ValueError:
                            batch_results_map[idx] = ("ì¤‘ë¦½", 0.5)
                    # ë©”íƒ€ë°ì´í„°-only ë¦¬ë·°ë„ ë³„ì  ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬
                    elif is_metadata_only(text) and rating is not None:
                        try:
                            rating_value = float(rating)
                            if rating_value >= 4.0:
                                batch_results_map[idx] = ("ê¸ì •", 0.9)
                            elif rating_value >= 3.0:
                                batch_results_map[idx] = ("ì¤‘ë¦½", 0.5)
                            else:
                                batch_results_map[idx] = ("ë¶€ì •", 0.1)
                        except (ValueError, TypeError):
                            batch_results_map[idx] = ("ì¤‘ë¦½", 0.5)
                    else:
                        # ì¼ë°˜ í…ìŠ¤íŠ¸ ë¦¬ë·°ëŠ” ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•´ ìˆ˜ì§‘
                        text_batch.append((idx, text))
                
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ë¦¬ë·°ëŠ” ëª¨ë¸ ì‚¬ìš©
                if text_batch:
                    text_only = [text for _, text in text_batch]
                    truncated_texts = [truncate_text_for_bert(text) for text in text_only]
                    model_results = sentiment_pipeline(truncated_texts, truncation=True, max_length=512)
                    
                    # ëª¨ë¸ ê²°ê³¼ë¥¼ ì¸ë±ìŠ¤ì— ë§¤í•‘
                    for (idx, _), res in zip(text_batch, model_results):
                        label, score = process_sentiment_result(res, sentiment_model_name)
                        batch_results_map[idx] = (label, score)
                
                # ì›ë˜ ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ì¶”ê°€
                for idx in range(len(batch_texts)):
                    label, score = batch_results_map[idx]
                    sentiment_labels.append(label)
                    sentiment_scores.append(score)
                    
            except Exception as e:
                st.warning(f"ë°°ì¹˜ {batch_idx+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                sentiment_labels.extend(['ì¤‘ë¦½'] * len(batch_texts))
                sentiment_scores.extend([0.5] * len(batch_texts))
        
        progress_bar.empty()
        status_text.empty()
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        df_preview_with_sentiment = df_preview_sorted.copy()
        df_preview_with_sentiment['ê°ì„±ë¶„ì„'] = sentiment_labels
        df_preview_with_sentiment['ê°ì„±ì ìˆ˜'] = [f"{s:.3f}" for s in sentiment_scores]
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬
        column_order = ['ìƒí˜¸ëª…', 'ì‹œêµ°êµ¬ëª…', 'í–‰ì •ë™ëª…', 'í‰ì ', 'ë¦¬ë·°', 'ê°ì„±ë¶„ì„', 'ê°ì„±ì ìˆ˜']
        df_preview_with_sentiment = df_preview_with_sentiment[column_order]
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state.preview_sentiment_result = df_preview_with_sentiment
        
        st.success(f"âœ… ê°ì„± ë¶„ì„ ì™„ë£Œ! {len(sentiment_labels):,}ê°œ ë¦¬ë·° ë¶„ì„ë¨")
        st.rerun()


def render_placeness_calculation(df_reviews, sbert_model, sentiment_pipeline, sentiment_model_name):
    """ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ ê³„ì‚° ì„¹ì…˜ ë Œë”ë§"""
    st.header("ğŸ“Š 1. ì¥ì†Œì„± ìš”ì¸ë³„ ì •ëŸ‰ ì ìˆ˜ ê³„ì‚°")
    st.caption(f"ìœ ì‚¬ë„ ì„ê³„ê°’: {SIMILARITY_THRESHOLD} (ì½”ë“œ ë‚´ ê³ ì •ê°’)")
    st.caption(f"âš ï¸ ì–¸ê¸‰ 0ì¸ ìš”ì¸ì€ fsi=0.5, Wi=0 ì²˜ë¦¬ë˜ì–´ Muì— ì˜í–¥ ì—†ìŒ")
    
    total_reviews_count = len(df_reviews)
    
    if st.button("ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ ê³„ì‚° ì‹œì‘", type="primary"):
        with st.spinner("12ê°œ ì¥ì†Œì„± ìš”ì¸ë³„ ì ìˆ˜ ê³„ì‚° ë° ì—°êµ¬ ì§€í‘œ ì‚°ì¶œ ì¤‘..."):
            try:
                df_place_scores, df_review_scores = calculate_place_scores(
                    df_reviews.copy(), 
                    sbert_model, 
                    sentiment_pipeline, 
                    ALL_FACTORS, 
                    similarity_threshold=SIMILARITY_THRESHOLD,
                    sentiment_model_name=sentiment_model_name
                )
                
                df_final_metrics = calculate_final_research_metrics(
                    df_place_scores, 
                    list(ALL_FACTORS.keys()), 
                    total_reviews_count
                )
                
                st.session_state.df_review_scores = df_review_scores
                st.session_state.df_final_metrics = df_final_metrics
                st.session_state.df_place_scores = df_place_scores
                
            except Exception as e:
                st.error(f"ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                st.code(traceback.format_exc())
    
    # ê²°ê³¼ í‘œì‹œ
    if st.session_state.df_final_metrics is not None:
        _render_placeness_results()


def _render_placeness_results():
    """ì¥ì†Œì„± ê³„ì‚° ê²°ê³¼ í‘œì‹œ"""
    st.header("ì¥ì†Œì„± ì¢…í•© ì ìˆ˜")
    
    df_final_metrics = st.session_state.df_final_metrics
    
    # Final_PlaceScore_Summaryì™€ ê°•ì /ì•½ì ë§Œ í‘œì‹œ
    display_summary_cols = ['cafe_name', 'Final_PlaceScore_Summary', 'ê°•ì _ìš”ì¸(+df+)', 'ì•½ì _ìš”ì¸(-df-)']
    if all(col in df_final_metrics.columns for col in display_summary_cols):
        st.dataframe(
            df_final_metrics[display_summary_cols].set_index('cafe_name'), 
            use_container_width=True
        )
    
    st.subheader("ì„¸ë¶€ ì§€í‘œ ì ìˆ˜ (fsi)")
    fsi_cols = ['cafe_name', 'ì¢…í•©_ì¥ì†Œì„±_ì ìˆ˜_Mu', 'ìš”ì¸_ì ìˆ˜_í‘œì¤€í¸ì°¨_Sigma'] + [f'ì ìˆ˜_{factor}' for factor in ALL_FACTORS.keys()]
    if all(col in df_final_metrics.columns for col in fsi_cols):
        st.dataframe(
            df_final_metrics[fsi_cols].set_index('cafe_name'), 
            use_container_width=True
        )
    
    # ê°€ì¤‘ì¹˜ ì •ë³´ í‘œì‹œ
    with st.expander("ğŸ“Š ê°€ì¤‘ì¹˜ (Wi) ìƒì„¸ ì •ë³´"):
        wi_cols = ['cafe_name'] + [f'Wi_{factor}' for factor in ALL_FACTORS.keys()]
        if all(col in df_final_metrics.columns for col in wi_cols):
            st.dataframe(
                df_final_metrics[wi_cols].set_index('cafe_name'), 
                use_container_width=True
            )
    
    # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
    csv = df_final_metrics.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "ì¥ì†Œì„± ìµœì¢… ì—°êµ¬ ì§€í‘œ CSV ë‹¤ìš´ë¡œë“œ (Wi, Mu, Sigma í¬í•¨)",
        data=csv,
        file_name="placeness_final_research_metrics.csv",
        mime="text/csv"
    )


def render_sentiment_analysis(df_reviews, sentiment_pipeline, sentiment_model_name):
    """ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ì„¹ì…˜ ë Œë”ë§"""
    st.header("2. ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ë° ì¹´í˜ë³„ í‰ê· ")
    
    if st.button("KoBERT ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ì‹œì‘", type="primary"):
        with st.spinner("ê°œë³„ ë¦¬ë·° ê¸ì •/ë¶€ì • ê°ì„± ì ìˆ˜ ê³„ì‚° ì¤‘ (KoBERT/KoELECTRA)..."):
            try:
                df_reviews_with_sentiment, df_avg_sentiment = run_sentiment_analysis(
                    df_reviews.copy(), 
                    sentiment_pipeline,
                    sentiment_model_name
                )
                
                st.session_state.df_reviews_with_sentiment = df_reviews_with_sentiment
                st.session_state.df_avg_sentiment = df_avg_sentiment
                
            except Exception as e:
                st.error(f"ê°ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                st.code(traceback.format_exc())
    
    # ê²°ê³¼ í‘œì‹œ
    if st.session_state.df_reviews_with_sentiment is not None and st.session_state.df_avg_sentiment is not None:
        st.subheader("âœ… ì¹´í˜ë³„ í‰ê·  ê°ì„± ì ìˆ˜")
        st.dataframe(st.session_state.df_avg_sentiment.set_index('cafe_name'), width='stretch')
        
        st.subheader("âœ… ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ê²°ê³¼ (ìƒ˜í”Œ)")
        sample_df = st.session_state.df_reviews_with_sentiment[['cafe_name', 'review_text', 'sentiment_label', 'sentiment_score']].head(20)
        st.dataframe(sample_df, width='stretch')
        
        # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        csv = st.session_state.df_reviews_with_sentiment.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name="review_sentiment_analysis.csv",
            mime="text/csv"
        )


def render_detailed_results():
    """ë¦¬ë·°ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì„¹ì…˜ ë Œë”ë§"""
    st.header("ğŸ“Š ë¦¬ë·°ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    
    has_sentiment = st.session_state.df_reviews_with_sentiment is not None
    has_placeness = st.session_state.df_review_scores is not None
    
    if not has_sentiment and not has_placeness:
        st.info("ğŸ‘† ìœ„ì˜ ë‘ ë¶„ì„ì„ ëª¨ë‘ ì‹¤í–‰í•˜ë©´ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        if has_sentiment and has_placeness:
            _render_merged_results()
        elif has_sentiment:
            st.info("ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ ê³„ì‚°ì„ ì‹¤í–‰í•˜ë©´ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # ì „ì²´ ë¦¬ë·° í‘œì‹œ
            display_cols = ['cafe_name', 'review_text', 'sentiment_label', 'sentiment_score']
            available_cols = [col for col in display_cols if col in st.session_state.df_reviews_with_sentiment.columns]
            st.dataframe(
                st.session_state.df_reviews_with_sentiment[available_cols], 
                use_container_width=True, 
                hide_index=True, 
            )
            st.caption(f"ì´ {len(st.session_state.df_reviews_with_sentiment):,}ê°œ ë¦¬ë·°")
        elif has_placeness:
            st.info("ê°ì„± ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # ì „ì²´ 12ê°œ ìš”ì¸ ì ìˆ˜ í‘œì‹œ
            factor_names = list(ALL_FACTORS.keys())
            factor_score_cols = [f'{factor}_ì ìˆ˜' for factor in factor_names]
            display_cols = ['cafe_name', 'review_text'] + factor_score_cols
            available_cols = [col for col in display_cols if col in st.session_state.df_review_scores.columns]
            
            # ì ìˆ˜ í¬ë§·íŒ…
            display_df = st.session_state.df_review_scores[available_cols].copy()
            for col in factor_score_cols:
                if col in display_df.columns:
                    display_df[col] = display_df[col].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")
            
            st.dataframe(
                display_df, 
                use_container_width=True, 
                hide_index=True, 
            )
            st.caption(f"ì´ {len(st.session_state.df_review_scores):,}ê°œ ë¦¬ë·° (12ê°œ ìš”ì¸ ì „ì²´ í‘œì‹œ)")
            
            # ìš”ì¸ë³„ í‚¤ì›Œë“œ ë¶„ì„ ì¶”ê°€
            st.markdown("---")
            visualize_factor_keywords(st.session_state.df_review_scores, factor_names, top_n=15)


def _render_merged_results():
    """ë³‘í•©ëœ ê²°ê³¼ í‘œì‹œ"""
    df_sentiment = st.session_state.df_reviews_with_sentiment.copy()
    df_placeness = st.session_state.df_review_scores.copy()
    
    df_sentiment['review_index'] = df_sentiment.index
    df_placeness['review_index'] = df_placeness['review_index']
    
    df_merged = pd.merge(
        df_sentiment[['review_index', 'cafe_name', 'review_text', 'sentiment_label', 'sentiment_score']],
        df_placeness,
        on=['review_index', 'cafe_name', 'review_text'],
        how='outer'
    )
    
    factor_names = list(ALL_FACTORS.keys())
    factor_score_cols = [f'{factor}_ì ìˆ˜' for factor in factor_names]
    display_cols = ['cafe_name', 'review_text', 'sentiment_label', 'sentiment_score'] + factor_score_cols
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
    available_cols = [col for col in display_cols if col in df_merged.columns]
    
    # ëˆ„ë½ëœ ìš”ì¸ ì»¬ëŸ¼ í™•ì¸
    missing_factors = [f for f in factor_names if f'{f}_ì ìˆ˜' not in df_merged.columns]
    if missing_factors:
        st.warning(f"âš ï¸ ë‹¤ìŒ ìš”ì¸ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_factors)}")
    
    st.subheader("âœ… ë¦¬ë·°ë³„ ê°ì„± ë¶„ì„ + ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ (ì „ì²´ 12ê°œ ìš”ì¸)")
    st.caption(f"ì´ {len(df_merged):,}ê°œ ë¦¬ë·° ì¤‘ í•„í„°ë§ëœ ê²°ê³¼ í‘œì‹œ")
    
    # í•„í„° ì˜µì…˜
    col1, col2 = st.columns(2)
    with col1:
        selected_cafe = st.selectbox(
            "ì¹´í˜ ì„ íƒ (ì „ì²´ ë³´ê¸°)",
            options=['ì „ì²´'] + sorted(df_merged['cafe_name'].unique().tolist()),
            key="review_detail_cafe_filter"
        )
    with col2:
        selected_sentiment = st.selectbox(
            "ê°ì„± í•„í„°",
            options=['ì „ì²´', 'ê¸ì •', 'ë¶€ì •'],
            key="review_detail_sentiment_filter"
        )
    
    # í•„í„°ë§
    filtered_df = df_merged.copy()
    if selected_cafe != 'ì „ì²´':
        filtered_df = filtered_df[filtered_df['cafe_name'] == selected_cafe]
    if selected_sentiment != 'ì „ì²´':
        filtered_df = filtered_df[filtered_df['sentiment_label'] == selected_sentiment]
    
    # ê²°ê³¼ í‘œì‹œ
    if len(filtered_df) > 0:
        display_df = filtered_df[available_cols].copy()
        
        # ì ìˆ˜ í¬ë§·íŒ…
        for col in factor_score_cols:
            if col in display_df.columns:
                display_df[col] = display_df[col].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")
        
        if 'sentiment_score' in display_df.columns:
            display_df['sentiment_score'] = display_df['sentiment_score'].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")
        
        # ì „ì²´ ë¦¬ë·° í‘œì‹œ (ë†’ì´ë¥¼ í¬ê²Œ ì„¤ì •í•˜ì—¬ ìŠ¤í¬ë¡¤ ê°€ëŠ¥)
        st.dataframe(
            display_df,
            use_container_width=True,
            hide_index=True,
        )

        st.caption(f"ì´ {len(filtered_df):,}ê°œ ë¦¬ë·° í‘œì‹œ (12ê°œ ìš”ì¸ ì „ì²´)")
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        csv = filtered_df[available_cols].to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name="review_detailed_analysis.csv",
            mime="text/csv"
        )
        
        # ìš”ì¸ë³„ í‚¤ì›Œë“œ ë¶„ì„ ì¶”ê°€
        st.markdown("---")
        factor_names = list(ALL_FACTORS.keys())
        visualize_factor_keywords(filtered_df, factor_names, top_n=15)
    else:
        st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")


def visualize_factor_keywords(df_review_scores, factor_names, top_n=15, top_reviews_per_factor=200):
    """
    ê° ìš”ì¸ë³„ë¡œ TF-IDFë¥¼ ì´ìš©í•˜ì—¬ 'íŠ¹ìƒ‰ ìˆëŠ”' ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
    ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ ë¦¬ë·°ì—ì„œë§Œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        df_review_scores: ë¦¬ë·°ë³„ ìš”ì¸ ì ìˆ˜/ìœ ì‚¬ë„ DataFrame
        factor_names: ìš”ì¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        top_n: ìƒìœ„ Nê°œ í‚¤ì›Œë“œ í‘œì‹œ
        top_reviews_per_factor: ê° ìš”ì¸ë³„ë¡œ ìœ ì‚¬ë„ ìƒìœ„ ëª‡ ê°œ ë¦¬ë·°ë¥¼ ì‚¬ìš©í• ì§€ (ê¸°ë³¸ê°’: 200)
    """
    st.subheader("ğŸ” ìš”ì¸ë³„ í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„ (TF-IDF ê¸°ë°˜)")
    st.info(f"ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ {top_reviews_per_factor}ê°œ ë¦¬ë·°ì—ì„œë§Œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. TF-IDFë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì¥ì†Œì„± ìš”ì¸ì„ ê°€ì¥ ì˜ ëŒ€í‘œí•˜ëŠ” ì°¨ë³„í™”ëœ ë‹¨ì–´ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    
    # 1. ìš”ì¸ë³„ í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    # ê° ìš”ì¸ì— ë§¤ì¹­ëœ ë¦¬ë·° ì¤‘ ìœ ì‚¬ë„ ìƒìœ„ ë¦¬ë·°ë§Œ ì‚¬ìš©
    factor_documents = []
    valid_factors = []  # ë¦¬ë·°ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” ìš”ì¸ë§Œ ì¶”ì 
    
    for factor in factor_names:
        score_col = f'{factor}_ì ìˆ˜'
        sim_col = f'{factor}_ìœ ì‚¬ë„'
        
        if score_col not in df_review_scores.columns:
            factor_documents.append("")
            continue
            
        # í•´ë‹¹ ìš”ì¸ì— ë§¤ì¹­ëœ ë¦¬ë·°ë§Œ í•„í„°ë§
        relevant_df = df_review_scores[
            pd.to_numeric(df_review_scores[score_col], errors='coerce').notnull()
        ].copy()
        
        if not relevant_df.empty:
            # ìœ ì‚¬ë„ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ, ì—†ìœ¼ë©´ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            if sim_col in relevant_df.columns:
                # ìœ ì‚¬ë„ ìƒìœ„ ë¦¬ë·°ë§Œ ì„ íƒ
                top_relevant_df = relevant_df.sort_values(by=sim_col, ascending=False).head(top_reviews_per_factor)
            else:
                # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                top_relevant_df = relevant_df.sort_values(by=score_col, ascending=False).head(top_reviews_per_factor)
            
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (í•œê¸€ë§Œ ë‚¨ê¸°ê¸°)
            text = " ".join(top_relevant_df['review_text'].astype(str).tolist())
            text = re.sub(r'[^ê°€-í£\s]', '', text)  # í•œê¸€ê³¼ ê³µë°±ë§Œ ë‚¨ê¹€
            factor_documents.append(text)
            valid_factors.append(factor)
        else:
            # ë§¤ì¹­ëœ ë¦¬ë·°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ì¶”ê°€ (ì¸ë±ìŠ¤ ìœ ì§€ë¥¼ ìœ„í•´)
            factor_documents.append("")
    
    if not any(factor_documents):
        st.warning("ë¶„ì„í•  í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 2. TF-IDF ë²¡í„°í™”
    # ë¶ˆìš©ì–´ ì„¤ì • (ëª¨ë“  ìš”ì¸ì—ì„œ ê³µí†µì ìœ¼ë¡œ ë„ˆë¬´ ë§ì´ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ë“¤ ì œê±°)
    stop_words = [
        'ì¹´í˜', 'ë„ˆë¬´', 'ì§„ì§œ', 'ì •ë§', 'ë§ì´', 'ê°€ì„œ', 'ë¨¹ê³ ', 'ìˆëŠ”', 'í•˜ëŠ”', 'ê·¸ë¦¬ê³ ', 'ê·¸ë˜ì„œ', 
        'ì¢‹ì•„ìš”', 'ìˆì–´ìš”', 'ê°™ì•„ìš”', 'ë§›ìˆì–´ìš”', 'ë¶„ìœ„ê¸°', 'ìƒê°', 'ëŠë‚Œ', 'ë°©ë¬¸', 'ê³³', 'ê²ƒ', 'ìˆ˜',
        'ìˆìŠµë‹ˆë‹¤', 'ìˆì—ˆ', 'ìˆê³ ', 'ìˆëŠ”ë°', 'ìˆì–´ì„œ', 'ìˆì–´', 'ìˆìŒ',
        'ì¢‹ìŠµë‹ˆë‹¤', 'ì¢‹ì•˜', 'ì¢‹ê³ ', 'ì¢‹ì€', 'ì¢‹ì•„', 'ì¢‹ë‹¤', 'ì¢‹ìŒ',
        'ë§›ìˆìŠµë‹ˆë‹¤', 'ë§›ìˆì—ˆ', 'ë§›ìˆê³ ', 'ë§›ìˆëŠ”', 'ë§›ìˆì–´',
        'ì´ê±°', 'ê·¸ê±°', 'ì €ê±°', 'ì´ê²ƒ', 'ê·¸ê²ƒ', 'ì €ê²ƒ',
        'ê·¸ëŸ°ë°', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜',
        'ì´ëŸ°', 'ê·¸ëŸ°', 'ì €ëŸ°', 'ì´ë ‡ê²Œ', 'ê·¸ë ‡ê²Œ', 'ì €ë ‡ê²Œ',
        'ë•Œë¬¸', 'ìœ„í•´', 'í†µí•´', 'ëŒ€í•´', 'ê´€ë ¨', 'ë”°ë¼',
        'ìë¦¬', 'ìë¦¬ê°€', 'ìë¦¬ë„', 'ìë¦¬ë¥¼', 'ìë¦¬ì—',
        'ë§¤ì¥', 'ë§¤ì¥ì´', 'ë§¤ì¥ë„', 'ë§¤ì¥ì„', 'ë§¤ì¥ì—',
        'ì‚¬ëŒ', 'ì‚¬ëŒì´', 'ì‚¬ëŒë“¤', 'ì‚¬ëŒë„',
        # ìŒë£Œ/ìŒì‹ ê´€ë ¨ ì¼ë°˜ ë‹¨ì–´
        'ì»¤í”¼', 'ì»¤í”¼ë„', 'ì»¤í”¼ë¥¼', 'ì»¤í”¼ê°€', 'ì»¤í”¼ëŠ”',
        'ìŒë£Œ', 'ìŒë£Œë„', 'ìŒë£Œë¥¼',
        'ë””ì €íŠ¸', 'ë””ì €íŠ¸ë„',
        # ì¼ë°˜ í˜•ìš©ì‚¬/ë¶€ì‚¬
        'ë‹¤ì–‘í•œ', 'ë‹¤ì–‘', 'ë‹¤ë¥¸', 'ë§¤ìš°', 'ì•„ì£¼', 'ì •ë§ë¡œ',
        'ìˆë‹¤', 'ìˆì–´', 'ìˆê³ ', 'ìˆëŠ”ë°', 'ìˆì–´ì„œ', 'ìˆìŒ'
    ]
    
    try:
        tfidf_vectorizer = TfidfVectorizer(
            max_features=1000, 
            stop_words=stop_words,
            token_pattern=r"(?u)\b\w\w+\b"  # 2ê¸€ì ì´ìƒ ë‹¨ì–´ë§Œ
        )
        tfidf_matrix = tfidf_vectorizer.fit_transform(factor_documents)
        feature_names = tfidf_vectorizer.get_feature_names_out()
    except ValueError as e:
        st.warning(f"TF-IDF ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜, ëª¨ë“  ë‹¨ì–´ê°€ ë¶ˆìš©ì–´ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
        return
    
    # 3. ì‹œê°í™”
    tabs = st.tabs(factor_names)
    
    for i, factor in enumerate(factor_names):
        with tabs[i]:
            score_col = f'{factor}_ì ìˆ˜'
            sim_col = f'{factor}_ìœ ì‚¬ë„'
            
            if score_col not in df_review_scores.columns:
                st.warning(f"ë°ì´í„°ì— {score_col} ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # í•´ë‹¹ ìš”ì¸ ì ìˆ˜ê°€ ìˆëŠ”(ë§¤ì¹­ëœ) ë¦¬ë·°ë“¤ë§Œ ì¶”ì¶œ
            relevant_df = df_review_scores[
                pd.to_numeric(df_review_scores[score_col], errors='coerce').notnull()
            ].copy()
            
            if relevant_df.empty or not factor_documents[i].strip():
                st.write("ë§¤ì¹­ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # -------------------------------------------------------
            # [ê²€ì¦ ë°©ë²• 1] ìœ ì‚¬ë„ ìƒìœ„ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
            # -------------------------------------------------------
            st.markdown(f"#### 1. '{factor}'ì™€ ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ë¦¬ë·° Top 10")
            
            # ìœ ì‚¬ë„ ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì‚¬ìš©, ì—†ë‹¤ë©´ ì ìˆ˜ ê¸°ì¤€
            if sim_col in relevant_df.columns:
                top_reviews = relevant_df.sort_values(by=sim_col, ascending=False).head(10)
                for idx, row in top_reviews.iterrows():
                    score_val = row[score_col] if pd.notna(row[score_col]) else "N/A"
                    sim_val = row[sim_col] if pd.notna(row[sim_col]) else "N/A"
                    st.success(f"**ìœ ì‚¬ë„ {sim_val:.3f} | ì ìˆ˜ {score_val:.3f}**: {row['review_text']}")
            else:
                st.warning("ìœ ì‚¬ë„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.")
                top_reviews = relevant_df.sort_values(by=score_col, ascending=False).head(10)
                for idx, row in top_reviews.iterrows():
                    score_val = row[score_col] if pd.notna(row[score_col]) else "N/A"
                    st.success(f"**ì ìˆ˜ {score_val:.3f}**: {row['review_text']}")
            
            # -------------------------------------------------------
            # [ê²€ì¦ ë°©ë²• 2] TF-IDF ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ì„ (Bar Chart)
            # -------------------------------------------------------
            st.markdown(f"#### 2. '{factor}' ê´€ë ¨ ë¦¬ë·° ë‚´ ì£¼ìš” í‚¤ì›Œë“œ")
            
            # í•´ë‹¹ ìš”ì¸(ë¬¸ì„œ)ì˜ TF-IDF ì ìˆ˜ ê°€ì ¸ì˜¤ê¸°
            tfidf_scores = tfidf_matrix[i].toarray().flatten()
            
            # í•´ë‹¹ ìš”ì¸ ë‚´ì—ì„œì˜ ë‹¨ì–´ ë¹ˆë„ë„ ê³„ì‚° (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)
            # TF-IDF ì ìˆ˜ì™€ ìš”ì¸ ë‚´ ë¹ˆë„ë¥¼ ê²°í•©í•˜ì—¬ ë” ì •í™•í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            factor_text = factor_documents[i]
            factor_word_counts = Counter(factor_text.split())
            total_words_in_factor = sum(factor_word_counts.values())
            
            # TF-IDF ì ìˆ˜ì™€ ìš”ì¸ ë‚´ ìƒëŒ€ ë¹ˆë„ë¥¼ ê²°í•©í•œ ì ìˆ˜ ê³„ì‚°
            hybrid_scores = []
            for idx, word in enumerate(feature_names):
                tfidf_score = tfidf_scores[idx]
                # í•´ë‹¹ ìš”ì¸ ë‚´ì—ì„œì˜ ìƒëŒ€ ë¹ˆë„ (0~1)
                word_freq_in_factor = factor_word_counts.get(word, 0) / max(total_words_in_factor, 1)
                # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜: TF-IDF * (1 + ìš”ì¸ ë‚´ ìƒëŒ€ ë¹ˆë„)
                # ì´ë ‡ê²Œ í•˜ë©´ TF-IDFê°€ ë†’ê³  í•´ë‹¹ ìš”ì¸ì—ì„œë„ ìì£¼ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ê°€ ìš°ì„ ìˆœìœ„ê°€ ë†’ì•„ì§
                hybrid_score = tfidf_score * (1 + word_freq_in_factor * 2)
                if hybrid_score > 0:
                    hybrid_scores.append((word, hybrid_score, tfidf_score, word_freq_in_factor))
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            hybrid_scores.sort(key=lambda x: x[1], reverse=True)
            top_keywords = hybrid_scores[:top_n]
            
            if top_keywords:
                # ë°ì´í„°í”„ë ˆì„ ë³€í™˜ (í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì‚¬ìš©)
                df_keywords = pd.DataFrame(
                    [(word, hybrid_score) for word, hybrid_score, _, _ in top_keywords],
                    columns=['ë‹¨ì–´', 'í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜']
                )
                df_keywords = df_keywords.sort_values('í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜', ascending=True)
                
                # Streamlit Bar Chart
                st.bar_chart(df_keywords.set_index('ë‹¨ì–´'), height=400)
                
                # ìƒì„¸ í…Œì´ë¸” (TF-IDF ì ìˆ˜ì™€ ë¹ˆë„ ì •ë³´ í¬í•¨)
                with st.expander("ìƒì„¸ í‚¤ì›Œë“œ ì ìˆ˜ ë³´ê¸°"):
                    df_detail = pd.DataFrame(
                        [(word, f"{hybrid_score:.4f}", f"{tfidf_score:.4f}", f"{freq:.4f}") 
                         for word, hybrid_score, tfidf_score, freq in top_keywords],
                        columns=['ë‹¨ì–´', 'í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜', 'TF-IDF ì ìˆ˜', 'ìš”ì¸ ë‚´ ìƒëŒ€ ë¹ˆë„']
                    )
                    st.dataframe(df_detail, use_container_width=True, hide_index=True)
                    st.caption("í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ = TF-IDF Ã— (1 + ìš”ì¸ ë‚´ ìƒëŒ€ ë¹ˆë„ Ã— 2)")
            else:
                st.write("ìœ ì˜ë¯¸í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            # -------------------------------------------------------
            # [ê²€ì¦ ë°©ë²• 3] ê¸ì • ë¦¬ë·°ë§Œ í•„í„°ë§í•˜ì—¬ ë³´ê¸°
            # -------------------------------------------------------
            st.markdown(f"#### 3. '{factor}' ì ìˆ˜ê°€ ë†’ì€(0.9 ì´ìƒ) ê¸ì • ë¦¬ë·° íŒ¨í„´")
            high_score_df = relevant_df[
                pd.to_numeric(relevant_df[score_col], errors='coerce') >= 0.9
            ]
            
            if not high_score_df.empty:
                display_cols = ['review_text', score_col]
                if sim_col in high_score_df.columns:
                    display_cols.insert(1, sim_col)
                st.dataframe(
                    high_score_df[display_cols].sort_values(by=score_col, ascending=False),
                    use_container_width=True,
                    hide_index=True,
                )
                st.caption(f"ì´ {len(high_score_df)}ê°œ ë¦¬ë·° (ì ìˆ˜ 0.9 ì´ìƒ)")
            else:
                st.info("0.9ì  ì´ìƒì˜ ë§¤ìš° ê¸ì •ì ì¸ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # -------------------------------------------------------
            # [ê²€ì¦ ë°©ë²• 4] í†µê³„ ì •ë³´
            # -------------------------------------------------------
            st.markdown(f"#### 4. '{factor}' ê´€ë ¨ í†µê³„")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ê´€ë ¨ ë¦¬ë·° ìˆ˜", f"{len(relevant_df):,}ê°œ")
            with col2:
                avg_score = pd.to_numeric(relevant_df[score_col], errors='coerce').mean()
                st.metric("í‰ê·  ì ìˆ˜", f"{avg_score:.3f}" if pd.notna(avg_score) else "N/A")
            with col3:
                if sim_col in relevant_df.columns:
                    avg_sim = pd.to_numeric(relevant_df[sim_col], errors='coerce').mean()
                    st.metric("í‰ê·  ìœ ì‚¬ë„", f"{avg_sim:.3f}" if pd.notna(avg_sim) else "N/A")
                else:
                    st.metric("í‰ê·  ìœ ì‚¬ë„", "N/A")
            with col4:
                high_count = len(relevant_df[pd.to_numeric(relevant_df[score_col], errors='coerce') >= 0.9])
                st.metric("ê¸ì • ë¦¬ë·° (â‰¥0.9)", f"{high_count}ê°œ")
            
            # -------------------------------------------------------
            # [ê²€ì¦ ë°©ë²• 5] í–‰ì •êµ¬ë³„ ìƒìœ„ 10% ì¹´í˜ ë¶„í¬ ì‹œê°í™”
            # -------------------------------------------------------
            st.markdown(f"#### 5. '{factor}' ì ìˆ˜ ìƒìœ„ 10% ì¹´í˜ í–‰ì •êµ¬ë³„ ë¶„í¬")
            
            # df_place_scoresì—ì„œ í•´ë‹¹ ìš”ì¸ ì ìˆ˜ ìƒìœ„ 10% ì¹´í˜ ì¶”ì¶œ
            if 'df_place_scores' in st.session_state and st.session_state.df_place_scores is not None:
                df_place_scores = st.session_state.df_place_scores
                factor_score_col = f'ì ìˆ˜_{factor}'
                
                if factor_score_col in df_place_scores.columns:
                    # ì ìˆ˜ê°€ ìˆëŠ” ì¹´í˜ë§Œ í•„í„°ë§
                    valid_scores = df_place_scores[
                        pd.to_numeric(df_place_scores[factor_score_col], errors='coerce').notna()
                    ].copy()
                    
                    if not valid_scores.empty:
                        # ìƒìœ„ 10% ì„ê³„ê°’ ê³„ì‚°
                        threshold = valid_scores[factor_score_col].quantile(0.9)
                        top_10_percent = valid_scores[valid_scores[factor_score_col] >= threshold].copy()
                        
                        # ì›ë³¸ ë°ì´í„°ì—ì„œ ì‹œêµ°êµ¬ëª… ê°€ì ¸ì˜¤ê¸°
                        df_reviews_for_district = None
                        if 'df_reviews' in st.session_state and st.session_state.df_reviews is not None:
                            df_reviews_for_district = st.session_state.df_reviews.copy()
                        
                        # ì‹œêµ°êµ¬ëª… ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì›ë³¸ CSVì—ì„œ ë¡œë“œ
                        if df_reviews_for_district is None or 'ì‹œêµ°êµ¬ëª…' not in df_reviews_for_district.columns:
                            try:
                                from pathlib import Path
                                from modules.config import GOOGLE_REVIEW_SAMPLE_CSV
                                df_reviews_for_district = load_csv_raw(Path(GOOGLE_REVIEW_SAMPLE_CSV))
                                
                                # ì»¬ëŸ¼ëª… ì •ê·œí™” (ìƒí˜¸ëª… -> cafe_name)
                                if 'ìƒí˜¸ëª…' in df_reviews_for_district.columns and 'cafe_name' not in df_reviews_for_district.columns:
                                    df_reviews_for_district['cafe_name'] = df_reviews_for_district['ìƒí˜¸ëª…']
                            except Exception as e:
                                st.warning(f"ì‹œêµ°êµ¬ëª… ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                                df_reviews_for_district = None
                        
                        if df_reviews_for_district is not None and 'ì‹œêµ°êµ¬ëª…' in df_reviews_for_district.columns:
                            # cafe_name ì»¬ëŸ¼ í™•ì¸ ë° ìƒì„±
                            if 'cafe_name' not in df_reviews_for_district.columns:
                                if 'ìƒí˜¸ëª…' in df_reviews_for_district.columns:
                                    df_reviews_for_district['cafe_name'] = df_reviews_for_district['ìƒí˜¸ëª…']
                                else:
                                    st.warning("cafe_name ë˜ëŠ” ìƒí˜¸ëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                    df_reviews_for_district = None
                            
                            if df_reviews_for_district is not None:
                                # original_cafe_nameì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ cafe_name ì‚¬ìš©
                                if 'original_cafe_name' in df_reviews_for_district.columns:
                                    cafe_to_district = df_reviews_for_district.groupby('original_cafe_name')['ì‹œêµ°êµ¬ëª…'].first().to_dict()
                                    # top_10_percentì˜ cafe_nameì—ì„œ ìœ„ì¹˜ ì •ë³´ ì œê±°í•˜ì—¬ original_cafe_name ì¶”ì¶œ
                                    top_10_percent['original_cafe_name'] = top_10_percent['cafe_name'].str.split().str[0]
                                    top_10_percent['ì‹œêµ°êµ¬ëª…'] = top_10_percent['original_cafe_name'].map(cafe_to_district)
                                else:
                                    # cafe_nameì—ì„œ ìœ„ì¹˜ ì •ë³´ ì œê±° ì‹œë„ (ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ì²« ë²ˆì§¸ ë¶€ë¶„)
                                    # ë¨¼ì € ì›ë³¸ cafe_nameìœ¼ë¡œ ë§¤í•‘ ì‹œë„
                                    cafe_to_district = df_reviews_for_district.groupby('cafe_name')['ì‹œêµ°êµ¬ëª…'].first().to_dict()
                                    
                                    # ì¹´í˜ëª…ì—ì„œ ìœ„ì¹˜ ì •ë³´ ì œê±° (ì‹œêµ°êµ¬ëª…ê³¼ í–‰ì •ë™ëª…ì´ ì¶”ê°€ëœ ê²½ìš°)
                                    # ì˜ˆ: "íˆ¬ì¸í”Œë ˆì´ìŠ¤ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™" -> "íˆ¬ì¸í”Œë ˆì´ìŠ¤"
                                    top_10_percent['base_cafe_name'] = top_10_percent['cafe_name'].str.split().str[0]
                                    
                                    # ë¨¼ì € ì „ì²´ cafe_nameìœ¼ë¡œ ë§¤í•‘ ì‹œë„, ì—†ìœ¼ë©´ base_cafe_nameìœ¼ë¡œ ì‹œë„
                                    top_10_percent['ì‹œêµ°êµ¬ëª…'] = top_10_percent['cafe_name'].map(cafe_to_district)
                                    # ë§¤í•‘ë˜ì§€ ì•Šì€ ê²½ìš° base_cafe_nameìœ¼ë¡œ ì¬ì‹œë„
                                    missing_mask = top_10_percent['ì‹œêµ°êµ¬ëª…'].isna()
                                    if missing_mask.any():
                                        base_cafe_to_district = df_reviews_for_district.groupby('cafe_name')['ì‹œêµ°êµ¬ëª…'].first().to_dict()
                                        # base_cafe_nameìœ¼ë¡œ ë§¤í•‘ ì‹œë„
                                        for idx in top_10_percent[missing_mask].index:
                                            base_name = top_10_percent.loc[idx, 'base_cafe_name']
                                            # base_nameê³¼ ì¼ì¹˜í•˜ëŠ” cafe_name ì°¾ê¸° (ë¶€ë¶„ ë§¤ì¹­)
                                            matched_district = None
                                            for cafe_name, district in base_cafe_to_district.items():
                                                if cafe_name.startswith(base_name) or base_name in cafe_name:
                                                    matched_district = district
                                                    break
                                            if matched_district:
                                                top_10_percent.loc[idx, 'ì‹œêµ°êµ¬ëª…'] = matched_district
                            
                            # ì‹œêµ°êµ¬ëª…ì´ ìˆëŠ” ì¹´í˜ë§Œ ì‚¬ìš©
                            top_10_percent_with_district = top_10_percent[
                                top_10_percent['ì‹œêµ°êµ¬ëª…'].notna()
                            ]
                            
                            if not top_10_percent_with_district.empty:
                                # í–‰ì •êµ¬ë³„ ì¹´í˜ ìˆ˜ ì§‘ê³„
                                district_counts = top_10_percent_with_district['ì‹œêµ°êµ¬ëª…'].value_counts().sort_values(ascending=True)
                                
                                # ë§‰ëŒ€ ê·¸ë˜í”„
                                df_district = pd.DataFrame({
                                    'í–‰ì •êµ¬': district_counts.index,
                                    'ìƒìœ„ 10% ì¹´í˜ ìˆ˜': district_counts.values
                                })
                                
                                st.bar_chart(df_district.set_index('í–‰ì •êµ¬'), height=400)
                                
                                # ìƒì„¸ í…Œì´ë¸”
                                with st.expander("í–‰ì •êµ¬ë³„ ìƒì„¸ ì •ë³´"):
                                    st.dataframe(
                                        df_district.sort_values('ìƒìœ„ 10% ì¹´í˜ ìˆ˜', ascending=False),
                                        use_container_width=True,
                                        hide_index=True
                                    )
                                
                                st.caption(f"ì´ {len(top_10_percent_with_district)}ê°œ ì¹´í˜ (ì ìˆ˜ ì„ê³„ê°’: {threshold:.3f} ì´ìƒ)")
                                
                                # ìœ„ë„/ê²½ë„ ê°€ì ¸ì˜¤ê¸° ë° ì§€ë„ ì‹œê°í™”
                                if CAFE_INFO_CSV.exists() and HAS_FOLIUM:
                                    try:
                                        # ì¹´í˜ ì •ë³´ CSVì—ì„œ ìœ„ë„/ê²½ë„ ê°€ì ¸ì˜¤ê¸°
                                        df_cafe_info = pd.read_csv(CAFE_INFO_CSV, encoding='utf-8-sig')
                                        
                                        # ìƒí˜¸ëª…, ì‹œêµ°êµ¬ëª…, í–‰ì •ë™ëª…ìœ¼ë¡œ ë§¤ì¹­
                                        # top_10_percent_with_districtì— ìœ„ë„/ê²½ë„ ì¶”ê°€
                                        top_10_percent_with_district['ìœ„ë„'] = None
                                        top_10_percent_with_district['ê²½ë„'] = None
                                        
                                        # ì¹´í˜ëª…ì—ì„œ ìœ„ì¹˜ ì •ë³´ ì œê±° (base_cafe_name ì‚¬ìš©)
                                        if 'base_cafe_name' not in top_10_percent_with_district.columns:
                                            top_10_percent_with_district['base_cafe_name'] = top_10_percent_with_district['cafe_name'].str.split().str[0]
                                        
                                        # í–‰ì •ë™ëª…ë„ ê°€ì ¸ì˜¤ê¸°
                                        if 'df_reviews' in st.session_state and st.session_state.df_reviews is not None:
                                            df_reviews = st.session_state.df_reviews
                                            if 'í–‰ì •ë™ëª…' in df_reviews.columns:
                                                if 'original_cafe_name' in df_reviews.columns:
                                                    cafe_to_dong = df_reviews.groupby('original_cafe_name')['í–‰ì •ë™ëª…'].first().to_dict()
                                                    top_10_percent_with_district['í–‰ì •ë™ëª…'] = top_10_percent_with_district.get('original_cafe_name', top_10_percent_with_district['base_cafe_name']).map(cafe_to_dong)
                                                else:
                                                    cafe_to_dong = df_reviews.groupby('cafe_name')['í–‰ì •ë™ëª…'].first().to_dict()
                                                    top_10_percent_with_district['í–‰ì •ë™ëª…'] = top_10_percent_with_district['cafe_name'].map(cafe_to_dong)
                                        
                                        # ì¹´í˜ ì •ë³´ì™€ ë§¤ì¹­
                                        for idx, row in top_10_percent_with_district.iterrows():
                                            cafe_name = row.get('base_cafe_name', row['cafe_name'].split()[0])
                                            district = row['ì‹œêµ°êµ¬ëª…']
                                            dong = row.get('í–‰ì •ë™ëª…', None)
                                            
                                            matched = None
                                            
                                            # ë§¤ì¹­ ìš°ì„ ìˆœìœ„:
                                            # 1. ì •í™•í•œ ìƒí˜¸ëª… ì¼ì¹˜ + ì‹œêµ°êµ¬ëª… + í–‰ì •ë™ëª…
                                            # 2. ì •í™•í•œ ìƒí˜¸ëª… ì¼ì¹˜ + ì‹œêµ°êµ¬ëª…
                                            # 3. ìƒí˜¸ëª…ì´ cafe_nameìœ¼ë¡œ ì‹œì‘ + ì‹œêµ°êµ¬ëª… + í–‰ì •ë™ëª…
                                            # 4. ìƒí˜¸ëª…ì´ cafe_nameìœ¼ë¡œ ì‹œì‘ + ì‹œêµ°êµ¬ëª…
                                            
                                            if dong and pd.notna(dong):
                                                # 1ìˆœìœ„: ì •í™•í•œ ì¼ì¹˜ + ì‹œêµ°êµ¬ëª… + í–‰ì •ë™ëª…
                                                matched = df_cafe_info[
                                                    (df_cafe_info['ìƒí˜¸ëª…'] == cafe_name) &
                                                    (df_cafe_info['ì‹œêµ°êµ¬ëª…'] == district) &
                                                    (df_cafe_info['í–‰ì •ë™ëª…'] == dong)
                                                ]
                                                
                                                if matched.empty:
                                                    # 2ìˆœìœ„: ìƒí˜¸ëª…ì´ cafe_nameìœ¼ë¡œ ì‹œì‘ + ì‹œêµ°êµ¬ëª… + í–‰ì •ë™ëª…
                                                    matched = df_cafe_info[
                                                        (df_cafe_info['ìƒí˜¸ëª…'].str.startswith(cafe_name, na=False)) &
                                                        (df_cafe_info['ì‹œêµ°êµ¬ëª…'] == district) &
                                                        (df_cafe_info['í–‰ì •ë™ëª…'] == dong)
                                                    ]
                                            else:
                                                # í–‰ì •ë™ëª…ì´ ì—†ìœ¼ë©´ ì‹œêµ°êµ¬ëª…ë§Œìœ¼ë¡œ ë§¤ì¹­
                                                # 1ìˆœìœ„: ì •í™•í•œ ì¼ì¹˜ + ì‹œêµ°êµ¬ëª…
                                                matched = df_cafe_info[
                                                    (df_cafe_info['ìƒí˜¸ëª…'] == cafe_name) &
                                                    (df_cafe_info['ì‹œêµ°êµ¬ëª…'] == district)
                                                ]
                                                
                                                if matched.empty:
                                                    # 2ìˆœìœ„: ìƒí˜¸ëª…ì´ cafe_nameìœ¼ë¡œ ì‹œì‘ + ì‹œêµ°êµ¬ëª…
                                                    matched = df_cafe_info[
                                                        (df_cafe_info['ìƒí˜¸ëª…'].str.startswith(cafe_name, na=False)) &
                                                        (df_cafe_info['ì‹œêµ°êµ¬ëª…'] == district)
                                                    ]
                                            
                                            if not matched.empty:
                                                # ì²« ë²ˆì§¸ ë§¤ì¹­ ì‚¬ìš©
                                                top_10_percent_with_district.loc[idx, 'ìœ„ë„'] = matched.iloc[0]['ìœ„ë„']
                                                top_10_percent_with_district.loc[idx, 'ê²½ë„'] = matched.iloc[0]['ê²½ë„']
                                        
                                        # ìœ„ë„/ê²½ë„ê°€ ìˆëŠ” ì¹´í˜ë§Œ í•„í„°ë§
                                        cafes_with_location = top_10_percent_with_district[
                                            top_10_percent_with_district['ìœ„ë„'].notna() & 
                                            top_10_percent_with_district['ê²½ë„'].notna()
                                        ]
                                        
                                        if not cafes_with_location.empty:
                                            st.markdown("##### ì§€ë„ ì‹œê°í™”")
                                            
                                            # ì„œìš¸ ì¤‘ì‹¬ ì¢Œí‘œ
                                            seoul_center = [37.5665, 126.9780]
                                            
                                            # Folium ì§€ë„ ìƒì„±
                                            m = folium.Map(
                                                location=seoul_center,
                                                zoom_start=11,
                                                tiles='OpenStreetMap'
                                            )
                                            
                                            # ë§ˆì»¤ ì¶”ê°€
                                            for idx, row in cafes_with_location.iterrows():
                                                lat = float(row['ìœ„ë„'])
                                                lng = float(row['ê²½ë„'])
                                                cafe_name = row['cafe_name']
                                                score = row[factor_score_col]
                                                
                                                # íŒì—… ì •ë³´
                                                popup_html = f"""
                                                <div style="font-family: Arial; min-width: 150px;">
                                                    <b>{cafe_name}</b><br>
                                                    {factor} ì ìˆ˜: {score:.3f}<br>
                                                    {row.get('ì‹œêµ°êµ¬ëª…', 'N/A')} {row.get('í–‰ì •ë™ëª…', '')}
                                                </div>
                                                """
                                                
                                                folium.Marker(
                                                    location=[lat, lng],
                                                    popup=folium.Popup(popup_html, max_width=300),
                                                    tooltip=f"{cafe_name} ({score:.3f})",
                                                    icon=folium.Icon(color='red', icon='info-sign')
                                                ).add_to(m)
                                            
                                            # ì§€ë„ í‘œì‹œ
                                            st_folium(m, width=700, height=500)
                                            st.caption(f"ì§€ë„ì— í‘œì‹œëœ ì¹´í˜: {len(cafes_with_location)}ê°œ / ì´ {len(top_10_percent_with_district)}ê°œ")
                                        else:
                                            st.info("ìœ„ë„/ê²½ë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ì¹´í˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                    except Exception as e:
                                        st.warning(f"ì§€ë„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                                elif not HAS_FOLIUM:
                                    st.info("ì§€ë„ ì‹œê°í™”ë¥¼ ìœ„í•´ foliumê³¼ streamlit-folium íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                            else:
                                st.info("ì‹œêµ°êµ¬ëª… ì •ë³´ê°€ ìˆëŠ” ì¹´í˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.info("ë¦¬ë·° ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("ìœ íš¨í•œ ì ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info(f"'{factor_score_col}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ì¥ì†Œì„± ì ìˆ˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¥ì†Œì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”.")

