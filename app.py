import streamlit as st
import pandas as pd
import numpy as np
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path
import warnings

warnings.filterwarnings("ignore")

# --- 1. ì¥ì†Œì„± ìš”ì¸ ì •ì˜ (Sentence-BERT Input) ---
FACTOR_DEFINITIONS = {
    "ë¬¼ë¦¬ì  íŠ¹ì„±": {
        "ì‹¬ë¯¸ì„±": "ì¸í…Œë¦¬ì–´, ì¡°ëª…, ê°€êµ¬, ìƒ‰ì±„ ë“± ì‹œê°ì  ì•„ë¦„ë‹¤ì›€ê³¼ ë¯¸ì  ì¦ê±°ì›€ì„ í†µí•´ ì‹¬ë¦¬ì  ìš•êµ¬ë¥¼ ì¶©ì¡±ì‹œí‚¤ëŠ” ì •ë„ì…ë‹ˆë‹¤. í‚¤ì›Œë“œ: ì•„ë¦„ë‹¤ì›€, ì˜ˆì¨, ë””ìì¸, ì¸í…Œë¦¬ì–´, ì¡°ëª…, ì„¸ë ¨ë¨, ê°ê°ì , ë¶„ìœ„ê¸°, ì‹œê°ì , ì¡°í™”ë¡œì›€, ë¯¸ì  ì¦ê±°ì›€",
        "í˜•íƒœì„±": "ê³µê°„ì˜ ì¤‘ì‹¬, ì¶•, ë°©í–¥ì„±, ê²½ê³„, ì—ì›ŒìŒˆì„ í†µí•´ êµ¬ì¡°ì  ì§ˆì„œë¥¼ êµ¬ì¶•í•˜ê³ , ê³µê°„ ì§€ê° ë° ì •ìœ„(Orientation)ì— ë„ì›€ì„ ì£¼ëŠ” ë¬¼ë¦¬ì  êµ¬ì„±ì…ë‹ˆë‹¤. í‚¤ì›Œë“œ: ì¤‘ì‹¬, ì¶•, ë°©í–¥ì„±, ê²½ê³„, ì—ì›ŒìŒˆ, ê°œë°©ê°, êµ¬ì¡°, ë°°ì¹˜, ë™ì„ , ê³µê°„ êµ¬ì„±, íš¨ìœ¨ì„±, ì§ˆì„œì •ì—°, ì²´ê³„ì ",
        "ê°ê°ì  ê²½í—˜": "ë°°ê²½ ìŒì•…, í–¥ê¸°, ê°€êµ¬ ì§ˆê°, ìƒ‰ì±„ ë“± ì˜¤ê°ì„ ìê·¹í•˜ëŠ” ì‹¤ë‚´ë””ìì¸ ìš”ì†Œê°€ ì¾Œì í•˜ê³  ë‹ë³´ì´ë©°, ì¥ì†Œì— ëŒ€í•œ íŠ¹ë³„í•œ ê¸°ì–µê³¼ ì˜ë¯¸ë¥¼ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. í‚¤ì›Œë“œ: ìŒì•…, í–¥ê¸°, ëƒ„ìƒˆ, ì§ˆê°, ì´‰ê°, ì˜¤ê°, ê°ê°ì , ì²­ê°, í›„ê°, ë¶„ìœ„ê¸°, ìƒ‰ì±„, ê¸°ì–µ",
        "ì ‘ê·¼ì„±": "ëŒ€ì¤‘êµí†µ ì ‘ê·¼, ë„ë³´ ê°€ëŠ¥ì„± ë“± ì¥ì†Œë¥¼ ì‰½ê²Œ ì°¾ì•„ì˜¤ê³  ì´ìš©í•  ìˆ˜ ìˆëŠ” ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ê³µê°„ì§€ê°ì˜ ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. í‚¤ì›Œë“œ: ì ‘ê·¼ì„±, ìœ„ì¹˜, ê±°ë¦¬, êµí†µ, ë²„ìŠ¤, ì§€í•˜ì² , ë„ë³´, ì´ë™, í¸ë¦¬í•¨, ì£¼ì°¨, ì§„ì…, Traffic accessibility, Walkability",
        "ì¾Œì ì„±": "ì±„ê´‘, ì˜¨ìŠµë„, ì²­ê²°, ì•ˆì „ ë“± ê³µê°„ ì´ìš©ìê°€ ëŠë¼ëŠ” ë¬¼ë¦¬ì  ì•ˆë½ê°ê³¼ ì¾Œì í•¨ì„ ì˜ë¯¸í•˜ë©°, ê³µê°„ì§€ê°ì˜ í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤. í‚¤ì›Œë“œ: ì²­ê²°, ì˜¨ë„, ì±„ê´‘, í†µí’, ìœ„ìƒ, ë°ìŒ, ëƒ‰ë‚œë°©, ê³µê¸°, ì •ëˆ, ì•ˆì „, ì•ˆë½í•¨, Safe and clean"
    },
    "í™œë™ì  íŠ¹ì„±": {
        "í™œë™ì„±": "ëŒ€í™”, ì—…ë¬´, íœ´ì‹, ì‹ì‚¬ ë“± ë‹¤ì–‘í•œ í™œë™ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ë£¨ì–´ì§€ëŠ” ì •ë„ë¥¼ ì˜ë¯¸í•˜ë©°, ê¸°ëŠ¥ì˜ ë³µí•©ì„±ê³¼ ììœ ë¡œìš´ í–‰ë™ ì„ íƒì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. í‚¤ì›Œë“œ: ëŒ€í™”, ì—…ë¬´, íšŒì˜, ì‹ì‚¬, íœ´ì‹, í™œë™, ëª¨ì„, ì¼, ì‘ì—…, ì´ìš©, ê¸°ëŠ¥ì  ë³µí•©ì„±, ë‹¤ì–‘ì„±",
        "ì‚¬íšŒì„±": "ë‹¤ë¥¸ ì‚¬ëŒë“¤ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–´ìš¸ë¦¬ê±°ë‚˜ êµë¥˜í•  ìˆ˜ ìˆëŠ” ê°œë°©ì ì´ê³  ì¹œê·¼í•œ ë¶„ìœ„ê¸°ë¥¼ ì˜ë¯¸í•˜ë©°, ê³µë™ ìœ ëŒ€ê° í˜•ì„± ë° ì‚¬íšŒì  ìš•êµ¬ë¥¼ ì¶©ì¡±ì‹œí‚µë‹ˆë‹¤. í‚¤ì›Œë“œ: êµë¥˜, ì†Œí†µ, ì¹œê·¼, ì¹œì ˆ, ì„œë¹„ìŠ¤, ì–´ìš¸ë¦¼, ëŒ€ì¸ ê´€ê³„, ì»¤ë®¤ë‹ˆí‹°, ê°œë°©ì , êµê°, ì‚¬íšŒì , í•¨ê»˜, íŒŒí‹°, Social participation",
        "ì°¸ì—¬ì„±": "ì´ìš©ìê°€ ì´ë²¤íŠ¸, ì²´í—˜, í´ë˜ìŠ¤ ë“± ê³µê°„ ë‚´ì—ì„œ ëŠ¥ë™ì ìœ¼ë¡œ ì°¸ì—¬í•˜ê³  ê²½í—˜í•  ìˆ˜ ìˆëŠ” ì •ë„ë¥¼ ì˜ë¯¸í•˜ë©°, í™˜ê²½ì— ì£¼ì²´ì ìœ¼ë¡œ ì˜í–¥ì„ ì£¼ë ¤ëŠ” í†µì œ ìš•êµ¬ë¥¼ ì¶©ì¡±ì‹œí‚µë‹ˆë‹¤. í‚¤ì›Œë“œ: ì°¸ì—¬, ì²´í—˜, í´ë˜ìŠ¤, ì›ë°ì´, ì›Œí¬ìˆ, í–‰ì‚¬, ì´ë²¤íŠ¸, í™œë™, ì§ì ‘, ê²½í—˜, ì£¼ì²´ì , Self participation"
    },
    "ì˜ë¯¸ì  íŠ¹ì„±": {
        "ê³ ìœ ì„±": "ë‹¤ë¥¸ ì¥ì†Œì™€ ì°¨ë³„í™”ë˜ëŠ” ë…íŠ¹í•œ ì½˜ì…‰íŠ¸ë‚˜ ìƒì§•ì  ë””ìì¸ìœ¼ë¡œ ì¥ì†Œë§Œì˜ ì •ì²´ì„±ì„ í˜•ì„±í•˜ë©°, ì´ìš©ìê°€ ìì•„ë¥¼ í‘œì¶œí•˜ëŠ” ìˆ˜ë‹¨ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤. í‚¤ì›Œë“œ: ë…íŠ¹, ê°œì„±, ì°¨ë³„í™”, ì»¨ì…‰, ìƒì§•, ìœ ë‹ˆí¬, ë…ì°½ì , ì•„ì´ë´í‹°í‹°, ê³ ìœ , ì •ì²´ì„±, Preference, Meaning, Personal identity",
        "ê¸°ì–µ/ê²½í—˜": "íŠ¹ë³„í•œ ì¶”ì–µì´ë‚˜ ì˜ë¯¸ ìˆëŠ” ê²½í—˜ì„ ì œê³µí•˜ì—¬ ì˜¤ë˜ ê¸°ì–µì— ë‚¨ìœ¼ë©°, ì‹¬ë¦¬ì  ìš”ì†Œê°€ ê°œì…ëœ ê±´ì¶•ì  ì²´í—˜ì„ í†µí•´ ì¥ì†Œì„±ì„ ì§€ì†ì‹œí‚µë‹ˆë‹¤. í‚¤ì›Œë“œ: ì¶”ì–µ, ê¸°ì–µ, ê²½í—˜, ê°ë™, ì¸ìƒì , íšŒìƒ, ìŠ¤í† ë¦¬, ì˜ë¯¸, íŠ¹ë³„í•¨, íšŒê³ , Functional attachment",
        "ì§€ì—­ ì •ì²´ì„±": "ì¥ì†Œê°€ ìœ„ì¹˜í•œ ì§€ì—­ì˜ ë¬¸í™”, ìƒì§•ì„ ë°˜ì˜í•˜ì—¬ ê³ ìœ í•œ ì§€ì—­ ì´ë¯¸ì§€ë¥¼ í˜•ì„±í•˜ë©°, ì§€ì—­ì„±ì´ë‚˜ ì „í†µì„± ë¶€ê°ì„ í†µí•´ ê°•í•œ ì¥ì†Œì„±ì„ ê°–ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ: ì§€ì—­ì„±, ì§€ì—­ ì´ë¯¸ì§€, ë¬¸í™”, ì „í†µ, ìƒì§•, ë¡œì»¬, ë™ë„¤, í•«í”Œë ˆì´ìŠ¤, ì§€ì—­ ê¸°ë°˜, Cultural image, Regional landmark",
        "ë¬¸í™”ì  ë§¥ë½": "ê³µê°„ì´ ìœ„ì¹˜í•œ ì§€ì—­ì˜ ì—­ì‚¬, ë¬¸í™”ì  ë°°ê²½, ìŠ¤í† ë¦¬ ë“±ì„ ë°˜ì˜í•˜ë©°, ë¬¸ëª…ê¶Œì˜ ë¬¸í™”ì  ì²´ê³„ì— ë”°ë¥¸ ì˜ë¯¸ì  ì§ˆì„œë¥¼ í†µí•´ ì¥ì†Œì˜ ë§¥ë½ì„ ê°•í™”í•©ë‹ˆë‹¤. í‚¤ì›Œë“œ: ì—­ì‚¬, ë¬¸í™”, ë°°ê²½, ìŠ¤í† ë¦¬, ì „í†µ, ì„œì‚¬, ì§€ì—­ì„±, ì˜ë¯¸, ë§¥ë½, ì˜¤ë˜ëœ"
    }
}

ALL_FACTORS = {k: v for outer_dict in FACTOR_DEFINITIONS.values() for k, v in outer_dict.items()}

# --- 2. ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì • ---
BASE_DIR = Path(__file__).resolve().parent
GOOGLE_REVIEW_SAMPLE_CSV = BASE_DIR / "google_reviews_scraped_cleaned.csv"

# --- 2-1. ì•Œê³ ë¦¬ì¦˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ---
SIMILARITY_THRESHOLD = 0.4  # ë¦¬ë·°ì™€ ìš”ì¸ ì •ì˜ ê°„ ìµœì†Œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (0.0~1.0)
# ê¶Œì¥ê°’: 0.5 (ì¤‘ê°„ í•„í„°ë§) - ë„ˆë¬´ ë‚®ìœ¼ë©´(0.3~0.4) ê´€ë ¨ ì—†ëŠ” ë¦¬ë·° í¬í•¨, ë„ˆë¬´ ë†’ìœ¼ë©´(0.7~0.8) ê´€ë ¨ ë¦¬ë·° ëˆ„ë½

# --- 3. ëª¨ë¸ ë¡œë“œ ë° ìºì‹± (Streamlit ì„±ëŠ¥ ìµœì í™”) ---
@st.cache_resource
def load_models():
    """Sentence-BERTì™€ ê°ì„± ë¶„ì„ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    # 1. Sentence-BERT ëª¨ë¸ ë¡œë“œ (ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°ìš©)
    with st.spinner("ëª¨ë¸ ë¡œë“œ ì¤‘: Sentence-BERT (ìœ ì‚¬ë„ìš©)..."):
        try:
            sbert_model = SentenceTransformer('jhgan/ko-sroberta-multitask')
        except Exception as e:
            st.warning(f"ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ëŒ€ì²´ ëª¨ë¸ ì‚¬ìš©: {e}")
            sbert_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')
    
    # 2. ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ (KoBERT/KoELECTRA ê¸°ë°˜)
    with st.spinner("ëª¨ë¸ ë¡œë“œ ì¤‘: KoELECTRA/KoBERT ê¸°ë°˜ ê°ì„±ë¶„ì„..."):
        try:
            # KoELECTRA ìš°ì„  ì‹œë„
            sentiment_model_name = "beomi/KcELECTRA-base"
            tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)
            model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name, num_labels=2)
            device = 0 if torch.cuda.is_available() else -1
            sentiment_pipeline = pipeline(
                "sentiment-analysis",
                model=model,
                tokenizer=tokenizer,
                device=device
            )
        except Exception as e:
            st.warning(f"KoELECTRA ë¡œë“œ ì‹¤íŒ¨, KoBERT ì‚¬ìš©: {e}")
            try:
                # KoBERT ëŒ€ì²´ ì‹œë„
                sentiment_model_name = "monologg/kobert-base-v1"
                tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)
                model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name, num_labels=2)
                device = 0 if torch.cuda.is_available() else -1
                sentiment_pipeline = pipeline(
                    "sentiment-analysis",
                    model=model,
                    tokenizer=tokenizer,
                    device=device
                )
            except Exception as e2:
                st.error(f"ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e2}")
                st.stop()
    
    return sbert_model, sentiment_pipeline

# --- 4. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ---
@st.cache_data
def load_data(file_path: Path):
    """ë¦¬ë·° ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    if not file_path.exists():
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    
    try:
        df = pd.read_csv(file_path, encoding="utf-8-sig")
    except UnicodeDecodeError:
        df = pd.read_csv(file_path, encoding="cp949")
    
    # ì»¬ëŸ¼ëª… ì •ê·œí™” (í•œêµ­ì–´ ì»¬ëŸ¼ëª… ì²˜ë¦¬)
    column_mapping = {
        "ìƒí˜¸ëª…": "cafe_name",
        "ë¦¬ë·°": "review_text",
        "cafe_name": "cafe_name",
        "review_text": "review_text"
    }
    
    for old_col, new_col in column_mapping.items():
        if old_col in df.columns and new_col not in df.columns:
            df[new_col] = df[old_col]
    
    # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
    if "cafe_name" not in df.columns or "review_text" not in df.columns:
        st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")
        st.stop()
    
    # ê²°ì¸¡ì¹˜ ì œê±°
    initial_count = len(df)
    initial_cafe_count = df['cafe_name'].nunique() if 'cafe_name' in df.columns else 0
    
    df = df[['cafe_name', 'review_text']].dropna()
    after_dropna_count = len(df)
    after_dropna_cafe_count = df['cafe_name'].nunique() if 'cafe_name' in df.columns else 0
    
    df = df[df['review_text'].astype(str).str.strip() != '']
    final_count = len(df)
    final_cafe_count = df['cafe_name'].nunique() if 'cafe_name' in df.columns else 0
    
    st.success(f"ë¦¬ë·° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {final_count}ê±´")
    st.info(f"ğŸ“Š ê³ ìœ  ì¹´í˜ ìˆ˜: {final_cafe_count}ê°œ (ì´ˆê¸°: {initial_cafe_count}ê°œ, ê²°ì¸¡ì¹˜ ì œê±° í›„: {after_dropna_cafe_count}ê°œ)")
    
    if initial_cafe_count > final_cafe_count:
        excluded = initial_cafe_count - final_cafe_count
        st.warning(f"âš ï¸ {excluded}ê°œ ì¹´í˜ê°€ ë¹ˆ ë¦¬ë·°ë¡œ ì¸í•´ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return df

# --- 5. ì•Œê³ ë¦¬ì¦˜ í•µì‹¬: ê°ì„± ë¶„ì„ ë° ìœ ì‚¬ë„ ê¸°ë°˜ ìš”ì¸ ì ìˆ˜ ê³„ì‚° ---
def calculate_place_scores(df_reviews, sbert_model, sentiment_pipeline, factor_defs, similarity_threshold=0.5):
    """
    Sentence-BERTì™€ ê°ì„± ë¶„ì„ì„ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œì„± ìš”ì¸ë³„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    ë¦¬ë·°ë³„ ì ìˆ˜ë„ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    st.subheader("1. Sentence-BERT ì„ë² ë”© ìƒì„±")
    
    # 1. ì¥ì†Œì„± ì •ì˜ ë¬¸ì¥ ì„ë² ë”© (ê³ ì • ë²¡í„°)
    factor_sentences = list(factor_defs.values())
    factor_names = list(factor_defs.keys())
    
    with st.spinner("ì¥ì†Œì„± ìš”ì¸ ì •ì˜ ì„ë² ë”© ìƒì„± ì¤‘..."):
        factor_embeddings = sbert_model.encode(factor_sentences, convert_to_tensor=True, show_progress_bar=False)
    
    # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸
    results_list = []
    review_scores_list = []  # ë¦¬ë·°ë³„ ì ìˆ˜ ì €ì¥
    
    # ì¹´í˜ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì²˜ë¦¬
    cafe_groups = df_reviews.groupby('cafe_name')
    total_cafes = len(cafe_groups)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, (cafe_name, group) in enumerate(cafe_groups):
        status_text.text(f"ì²˜ë¦¬ ì¤‘: {cafe_name} ({idx+1}/{total_cafes})")
        progress_bar.progress((idx + 1) / total_cafes)
        
        # 2. ê°œë³„ ë¦¬ë·° ì„ë² ë”©
        review_texts = group['review_text'].astype(str).tolist()
        review_indices = group.index.tolist()
        
        with st.spinner(f"{cafe_name} ë¦¬ë·° ì„ë² ë”© ìƒì„± ì¤‘..."):
            review_embeddings = sbert_model.encode(review_texts, convert_to_tensor=True, show_progress_bar=False)
        
        # 3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ë¦¬ë·° ë¬¸ì¥ vs. 12ê°œ ìš”ì¸ ì •ì˜ ë¬¸ì¥)
        similarity_matrix = cosine_similarity(
            review_embeddings.cpu().numpy(), 
            factor_embeddings.cpu().numpy()
        )
        
        # 4. ìš”ì¸ë³„ ì ìˆ˜ ì§‘ê³„
        cafe_scores = {'cafe_name': cafe_name}
        
        # ê° ë¦¬ë·°ë³„ë¡œ ìš”ì¸ ì ìˆ˜ ê³„ì‚°
        for review_idx, (review_text, review_original_idx) in enumerate(zip(review_texts, review_indices)):
            review_factor_scores = {
                'review_index': review_original_idx,
                'cafe_name': cafe_name,
                'review_text': review_text
            }
            
            # ê° ìš”ì¸ë³„ë¡œ ë°˜ë³µ
            for i, factor_name in enumerate(factor_names):
                similarity_score = similarity_matrix[review_idx, i]
                
                # ìœ ì‚¬ë„ ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ì—ë§Œ ì ìˆ˜ ê³„ì‚°
                if similarity_score >= similarity_threshold:
                    # í•´ë‹¹ ë¦¬ë·°ì— ëŒ€í•œ ê°ì„± ë¶„ì„
                    try:
                        sentiment_result = sentiment_pipeline([review_text])[0]
                        label = sentiment_result['label']
                        score = sentiment_result['score']
                        
                        # ê¸ì • í™•ë¥  ê³„ì‚°
                        if any(pos in str(label).upper() for pos in ['POSITIVE', 'ê¸ì •', 'LABEL_1', '1']):
                            positive_prob = score
                        else:
                            positive_prob = 1 - score
                        
                        # ìœ ì‚¬ë„ì™€ ê°ì„± ì ìˆ˜ë¥¼ ê²°í•© (ê°€ì¤‘ í‰ê· )
                        combined_score = 0.6 * similarity_score + 0.4 * positive_prob
                        review_factor_scores[f'{factor_name}_ì ìˆ˜'] = combined_score
                        review_factor_scores[f'{factor_name}_ìœ ì‚¬ë„'] = similarity_score
                    except Exception as e:
                        review_factor_scores[f'{factor_name}_ì ìˆ˜'] = np.nan
                        review_factor_scores[f'{factor_name}_ìœ ì‚¬ë„'] = similarity_score
                else:
                    review_factor_scores[f'{factor_name}_ì ìˆ˜'] = np.nan
                    review_factor_scores[f'{factor_name}_ìœ ì‚¬ë„'] = similarity_score
            
            review_scores_list.append(review_factor_scores)
        
        # ê° ìš”ì¸ë³„ë¡œ ë°˜ë³µ (ì¹´í˜ë³„ í‰ê·  ì ìˆ˜ ê³„ì‚°)
        for i, factor_name in enumerate(factor_names):
            # 4-1. ìœ ì‚¬ë„ ì„ê³„ê°’ ì´ìƒì¸ ë¬¸ì¥ ì„ ë³„
            relevant_review_indices = np.where(similarity_matrix[:, i] >= similarity_threshold)[0]
            
            if len(relevant_review_indices) > 0:
                relevant_texts = [review_texts[idx] for idx in relevant_review_indices]
                
                # 4-2. BERT ê°ì„± ë¶„ì„ ì ìš© (0~1 ê¸ì • ì ìˆ˜)
                try:
                    sentiment_results = sentiment_pipeline(relevant_texts)
                    
                    # ê°ì„± ì ìˆ˜ ì¶”ì¶œ (ë ˆì´ë¸”ì— ë”°ë¼ ê¸ì • í™•ë¥  ê³„ì‚°)
                    sentiment_scores = []
                    for res in sentiment_results:
                        label = res['label']
                        score = res['score']
                        
                        # ë ˆì´ë¸”ì´ 'POSITIVE', 'ê¸ì •', 'LABEL_1' ë“±ì¸ ê²½ìš°
                        if any(pos in str(label).upper() for pos in ['POSITIVE', 'ê¸ì •', 'LABEL_1', '1']):
                            sentiment_scores.append(score)
                        else:
                            sentiment_scores.append(1 - score)
                    
                    # 4-3. ì„¸ë¶€ í•­ëª© ìµœì¢… ì ìˆ˜ ì‚°ì¶œ (ì‚°ìˆ  í‰ê· )
                    avg_score = np.mean(sentiment_scores) if sentiment_scores else 0.5
                    cafe_scores[f'ì ìˆ˜_{factor_name}'] = avg_score
                    cafe_scores[f'ë¦¬ë·°ìˆ˜_{factor_name}'] = len(relevant_texts)
                    
                except Exception as e:
                    st.warning(f"{cafe_name} - {factor_name} ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
                    cafe_scores[f'ì ìˆ˜_{factor_name}'] = np.nan
                    cafe_scores[f'ë¦¬ë·°ìˆ˜_{factor_name}'] = 0
            else:
                # ê´€ë ¨ ë¦¬ë·°ê°€ ì—†ìœ¼ë©´ NaN ì²˜ë¦¬
                cafe_scores[f'ì ìˆ˜_{factor_name}'] = np.nan
                cafe_scores[f'ë¦¬ë·°ìˆ˜_{factor_name}'] = 0
        
        results_list.append(cafe_scores)
    
    progress_bar.empty()
    status_text.empty()
    
    df_cafe_scores = pd.DataFrame(results_list)
    df_review_scores = pd.DataFrame(review_scores_list)
    
    return df_cafe_scores, df_review_scores

# --- 6. ì•Œê³ ë¦¬ì¦˜ í•µì‹¬: ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ (KoBERT í™œìš©) ---
def run_sentiment_analysis(df_reviews, sentiment_pipeline):
    """
    ê°œë³„ ë¦¬ë·° í…ìŠ¤íŠ¸ì— ëŒ€í•´ KoBERT/KoELECTRA ê¸°ë°˜ ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    st.subheader("2. ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ (KoBERT/KoELECTRA ê¸°ë°˜)")
    
    review_texts = df_reviews['review_text'].astype(str).tolist()
    
    # ì§„í–‰ ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0)
    batch_size = 32
    total_batches = (len(review_texts) + batch_size - 1) // batch_size
    
    sentiment_scores = []
    
    for batch_idx in range(total_batches):
        start_idx = batch_idx * batch_size
        end_idx = min((batch_idx + 1) * batch_size, len(review_texts))
        batch_texts = review_texts[start_idx:end_idx]
        
        progress_bar.progress((batch_idx + 1) / total_batches)
        
        try:
            # KoBERT/KoELECTRA ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê¸ì • í™•ë¥ ì„ ì‚°ì¶œ
            batch_results = sentiment_pipeline(batch_texts)
            
            # ê¸ì • ì ìˆ˜ ì¶”ì¶œ
            for res in batch_results:
                label = res['label']
                score = res['score']
                
                if any(pos in str(label).upper() for pos in ['POSITIVE', 'ê¸ì •', 'LABEL_1', '1']):
                    sentiment_scores.append(score)
                else:
                    sentiment_scores.append(1 - score)
        except Exception as e:
            st.warning(f"ë°°ì¹˜ {batch_idx+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¤‘ë¦½ ì ìˆ˜ í• ë‹¹
            sentiment_scores.extend([0.5] * len(batch_texts))
    
    progress_bar.empty()
    
    # ë¦¬ë·° ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
    df_reviews = df_reviews.copy()
    df_reviews['sentiment_score'] = sentiment_scores
    
    # ê°ì„± ë ˆì´ë¸” ì¶”ê°€ (0.5 ê¸°ì¤€ìœ¼ë¡œ ê¸ì •/ë¶€ì • ë¶„ë¥˜)
    df_reviews['sentiment_label'] = df_reviews['sentiment_score'].apply(
        lambda x: 'ê¸ì •' if x >= 0.5 else 'ë¶€ì •'
    )
    
    # ì¹´í˜ë³„ í‰ê·  ê°ì„± ì ìˆ˜ ì‚°ì¶œ
    avg_sentiment = df_reviews.groupby('cafe_name')['sentiment_score'].mean().reset_index()
    avg_sentiment.rename(columns={'sentiment_score': 'í‰ê· _ë¦¬ë·°_ê°ì„±ì ìˆ˜'}, inplace=True)
    
    st.success("ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ë° ì¹´í˜ë³„ í‰ê·  ì‚°ì¶œ ì™„ë£Œ.")
    return df_reviews, avg_sentiment

# --- 7. Streamlit UI êµ¬ì„± ---
def main():
    st.title("ì¥ì†Œì„± ê¸°ë°˜ ê³µê°„ ì •ëŸ‰ í‰ê°€ ì‹œìŠ¤í…œ (LLM & BERT)")
    st.markdown("---")
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    file_path = GOOGLE_REVIEW_SAMPLE_CSV
    
    # 1. ëª¨ë¸ ë¡œë“œ
    sbert_model, sentiment_pipeline = load_models()
    
    # 2. ë°ì´í„° ë¡œë“œ
    if not file_path.exists():
        st.error(f"âš ï¸ ì—ëŸ¬: ë¦¬ë·° ë°ì´í„° íŒŒì¼ '{file_path.name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.info(f"ì˜ˆìƒ ê²½ë¡œ: {file_path}")
        return
    
    try:
        df_reviews = load_data(file_path)
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return
    
    if df_reviews.empty:
        st.warning("ë¡œë“œëœ ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° í†µê³„ í‘œì‹œ
    unique_cafes = df_reviews['cafe_name'].nunique()
    reviews_per_cafe = df_reviews.groupby('cafe_name').size()
    
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì¹´í˜ ìˆ˜", f"{unique_cafes:,}ê°œ")
    with col2:
        st.metric("í‰ê·  ë¦¬ë·° ìˆ˜/ì¹´í˜", f"{reviews_per_cafe.mean():.1f}ê°œ")
    with col3:
        st.metric("ìµœëŒ€ ë¦¬ë·° ìˆ˜/ì¹´í˜", f"{reviews_per_cafe.max()}ê°œ")
    
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    st.markdown("---")
    st.header("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    preview_cols = ['cafe_name', 'review_text']
    if len(df_reviews) > 0:
        preview_df = df_reviews[preview_cols].head(10000)
        st.dataframe(
            preview_df,
            use_container_width=True,
            hide_index=True,
            height=400
        )
        st.caption(f"ìƒìœ„ 10000ê°œ ë¦¬ë·° ë¯¸ë¦¬ë³´ê¸° (ì „ì²´ {len(df_reviews):,}ê°œ)")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'df_review_scores' not in st.session_state:
        st.session_state.df_review_scores = None
    if 'df_reviews_with_sentiment' not in st.session_state:
        st.session_state.df_reviews_with_sentiment = None
    
    # --- 3. ì‹¤í–‰ íŒŒíŠ¸: ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ ê³„ì‚° ---
    st.header("ğŸ“Š 1. ì¥ì†Œì„± ìš”ì¸ë³„ ì •ëŸ‰ ì ìˆ˜ ê³„ì‚°")
    st.caption(f"ìœ ì‚¬ë„ ì„ê³„ê°’: {SIMILARITY_THRESHOLD} (ì½”ë“œ ë‚´ ê³ ì •ê°’)")
    
    # Sentence-BERTë¥¼ ì‚¬ìš©í•œ ìš”ì¸ ì ìˆ˜ ê³„ì‚° ì‹¤í–‰
    if st.button("ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ ê³„ì‚° ì‹œì‘", type="primary"):
        with st.spinner("12ê°œ ì¥ì†Œì„± ìš”ì¸ë³„ ì ìˆ˜ ê³„ì‚° ì¤‘ (Sentence-BERT & Sentiment Analysis)..."):
            try:
                df_place_scores, df_review_scores = calculate_place_scores(
                    df_reviews.copy(), 
                    sbert_model, 
                    sentiment_pipeline, 
                    ALL_FACTORS, 
                    similarity_threshold=SIMILARITY_THRESHOLD
                )
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.df_review_scores = df_review_scores
                
                st.subheader("âœ… ì¹´í˜ë³„ ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ (0~1)")
                st.dataframe(df_place_scores.set_index('cafe_name'), use_container_width=True)
                
                # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
                csv = df_place_scores.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name="placeness_factor_scores.csv",
                    mime="text/csv"
                )
                
            except Exception as e:
                st.error(f"ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                st.code(traceback.format_exc())
    
    # --- 4. ì‹¤í–‰ íŒŒíŠ¸: ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ (KoBERT) ---
    st.header("2. ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ë° ì¹´í˜ë³„ í‰ê· ")
    
    # KoBERTë¥¼ ì‚¬ìš©í•œ ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ì‹¤í–‰
    if st.button("KoBERT ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ì‹œì‘", type="primary"):
        with st.spinner("ê°œë³„ ë¦¬ë·° ê¸ì •/ë¶€ì • ê°ì„± ì ìˆ˜ ê³„ì‚° ì¤‘ (KoBERT/KoELECTRA)..."):
            try:
                df_reviews_with_sentiment, df_avg_sentiment = run_sentiment_analysis(
                    df_reviews.copy(), 
                    sentiment_pipeline
                )
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.df_reviews_with_sentiment = df_reviews_with_sentiment
                
                st.subheader("âœ… ì¹´í˜ë³„ í‰ê·  ê°ì„± ì ìˆ˜")
                st.dataframe(df_avg_sentiment.set_index('cafe_name'), use_container_width=True)
                
                st.subheader("âœ… ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ê²°ê³¼ (ìƒ˜í”Œ)")
                sample_df = df_reviews_with_sentiment[['cafe_name', 'review_text', 'sentiment_label', 'sentiment_score']].head(20)
                st.dataframe(sample_df, use_container_width=True)
                
                # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
                csv = df_reviews_with_sentiment.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ğŸ“¥ ê°œë³„ ë¦¬ë·° ê°ì„± ë¶„ì„ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name="review_sentiment_analysis.csv",
                    mime="text/csv"
                )
                
            except Exception as e:
                st.error(f"ê°ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                st.code(traceback.format_exc())
    
    # --- 5. ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ í‘œì‹œ ---
    st.header("ğŸ“Š ë¦¬ë·°ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    
    # ë‘ ë¶„ì„ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
    has_sentiment = st.session_state.df_reviews_with_sentiment is not None
    has_placeness = st.session_state.df_review_scores is not None
    
    if not has_sentiment and not has_placeness:
        st.info("ğŸ‘† ìœ„ì˜ ë‘ ë¶„ì„ì„ ëª¨ë‘ ì‹¤í–‰í•˜ë©´ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        # ê²°ê³¼ ë³‘í•©
        if has_sentiment and has_placeness:
            # ë‘ ê²°ê³¼ë¥¼ ë³‘í•©
            df_sentiment = st.session_state.df_reviews_with_sentiment.copy()
            df_placeness = st.session_state.df_review_scores.copy()
            
            # ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
            df_sentiment['review_index'] = df_sentiment.index
            df_placeness['review_index'] = df_placeness['review_index']
            
            # ë³‘í•©
            df_merged = pd.merge(
                df_sentiment[['review_index', 'cafe_name', 'review_text', 'sentiment_label', 'sentiment_score']],
                df_placeness,
                on=['review_index', 'cafe_name', 'review_text'],
                how='outer'
            )
            
            # 12ê°œ ìš”ì¸ ì ìˆ˜ ì»¬ëŸ¼ ì¶”ì¶œ
            factor_names = list(ALL_FACTORS.keys())
            factor_score_cols = [f'{factor}_ì ìˆ˜' for factor in factor_names]
            
            # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
            display_cols = ['cafe_name', 'review_text', 'sentiment_label', 'sentiment_score'] + factor_score_cols
            
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
            available_cols = [col for col in display_cols if col in df_merged.columns]
            
            st.subheader("âœ… ë¦¬ë·°ë³„ ê°ì„± ë¶„ì„ + ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜")
            
            # í•„í„° ì˜µì…˜
            col1, col2 = st.columns(2)
            with col1:
                selected_cafe = st.selectbox(
                    "ì¹´í˜ ì„ íƒ (ì „ì²´ ë³´ê¸°)",
                    options=['ì „ì²´'] + sorted(df_merged['cafe_name'].unique().tolist()),
                    key="review_detail_cafe_filter"
                )
            with col2:
                selected_sentiment = st.selectbox(
                    "ê°ì„± í•„í„°",
                    options=['ì „ì²´', 'ê¸ì •', 'ë¶€ì •'],
                    key="review_detail_sentiment_filter"
                )
            
            # í•„í„°ë§
            filtered_df = df_merged.copy()
            if selected_cafe != 'ì „ì²´':
                filtered_df = filtered_df[filtered_df['cafe_name'] == selected_cafe]
            if selected_sentiment != 'ì „ì²´':
                filtered_df = filtered_df[filtered_df['sentiment_label'] == selected_sentiment]
            
            # ê²°ê³¼ í‘œì‹œ
            if len(filtered_df) > 0:
                display_df = filtered_df[available_cols].copy()
                
                # ì ìˆ˜ í¬ë§·íŒ… (ì†Œìˆ˜ì  3ìë¦¬)
                for col in factor_score_cols:
                    if col in display_df.columns:
                        display_df[col] = display_df[col].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")
                
                # ê°ì„± ì ìˆ˜ í¬ë§·íŒ…
                if 'sentiment_score' in display_df.columns:
                    display_df['sentiment_score'] = display_df['sentiment_score'].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")
                
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    hide_index=True,
                    height=600
                )
                
                st.caption(f"ì´ {len(filtered_df):,}ê°œ ë¦¬ë·° í‘œì‹œ")
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                csv = filtered_df[available_cols].to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ğŸ“¥ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name="review_detailed_analysis.csv",
                    mime="text/csv"
                )
            else:
                st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        elif has_sentiment:
            st.info("ì¥ì†Œì„± ìš”ì¸ ì ìˆ˜ ê³„ì‚°ì„ ì‹¤í–‰í•˜ë©´ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            sample_df = st.session_state.df_reviews_with_sentiment[['cafe_name', 'review_text', 'sentiment_label', 'sentiment_score']].head(50)
            st.dataframe(sample_df, use_container_width=True, hide_index=True, height=400)
        
        elif has_placeness:
            st.info("ê°ì„± ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ë¦¬ë·°ë³„ ìƒì„¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            sample_df = st.session_state.df_review_scores[['cafe_name', 'review_text'] + [f'{factor}_ì ìˆ˜' for factor in list(ALL_FACTORS.keys())[:5]]].head(50)
            st.dataframe(sample_df, use_container_width=True, hide_index=True, height=400)

if __name__ == "__main__":
    main()
